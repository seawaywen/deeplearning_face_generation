{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Face Generation\n",
    "In this project, you'll use generative adversarial networks to generate new images of faces.\n",
    "### Get the Data\n",
    "You'll be using two datasets in this project:\n",
    "- MNIST\n",
    "- CelebA\n",
    "\n",
    "Since the celebA dataset is complex and you're doing GANs in a project for the first time, we want you to test your neural network on MNIST before CelebA.  Running the GANs on MNIST will allow you to see how well your model trains sooner.\n",
    "\n",
    "If you're using [FloydHub](https://www.floydhub.com/), set `data_dir` to \"/input\" and use the [FloydHub data ID](http://docs.floydhub.com/home/using_datasets/) \"R5KrjnANiKVhLWAkpXhNBe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found mnist Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "# FloydHub - Use with data ID \"R5KrjnANiKVhLWAkpXhNBe\"\n",
    "#data_dir = '/input'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "helper.download_extract('mnist', data_dir)\n",
    "#helper.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "### MNIST\n",
    "As you're aware, the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits. You can view the first number of examples by changing `show_n_images`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f252d4d1da0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzsXXd8FVX2/97XSzolAUHEXcuKZVmx\ngAVQUUAF29pQsXcWxYKri4C7KhZ+dtoKKk2xi+4qItbVlaLACqIRRJAiYAjpL3nl/v6YnJMzkwlJ\nyDwIfub7+bxPXua9N3Pn3jv3nvI95yitNVy4cOGC4NnTDXDhwkXrgrsouHDhwgR3UXDhwoUJ7qLg\nwoULE9xFwYULFya4i4ILFy5MSNuioJTqr5T6Xim1Wil1V7qu48KFC2eh0sFTUEp5ARQC6AdgA4DF\nAC7SWn/r+MVcuHDhKNIlKRwNYLXW+ketdQ2AlwAMTtO1XLhw4SB8aTrvPgB+Fv9vAHBMQ19WSjkm\nriilQNKPfA8AHo+xBqZSqXrHrMf3FJRSAACrBGfXduv9OQl5Pa/XCwBIJpO7fL6G7itdsLve7m6D\nHTweT715ppTitu1sfK1zYGdzvQH8qrVu12gbG72LNEEpda1SaolSasku/JY7EQB8Ph8f8/nq1jm/\n3w+v18uTOhQKIRQKmc4VDocRDocRiUR29VYahWwDwePx1LsParPf7wdgvk9qu/x+MBiEx+MxLWxO\nISMjAxkZGQCAzMxMZGZmmu6Friv7fmeg9vt8PtMYOQXZvx6Px3asZd/uKYTD4XrHAoGAbXtDoZBp\nfGmuEuS9WL/bANY1pY3pkhQ2Augs/u9Ue4yhtZ4CYAqw65JCIBAAANTU1PCxZDKJaDQKAKioqODj\noVAI1dXVpt+Hw2FUVlZSe/i43+9HPB7flSbZwm6HpUUBgOladC+BQIAHOBaL8XHZzmQymRbpJhQK\nobS0lP/fsWMHACArK8t0HDDvbMFg0NTHtJBorVFeXu54OyW01vyQyP6kBSiRSJjmyZ5CRUUFb0DU\nd7FYjD+PRCI8L+T8BVBvQaupqUF2djYAoKSkpNGFualI16KwGMABSqmuMBaDCwFc7NTJ6cGgTpKD\nnZOTg+3btwMwHjzaQWTHE1KpFJ9L7mBKKUcXBVq8EokET4REIsGfe73eertndXU1/w4AL3RlZWV8\n39ZFzinEYjFuTyqV4jb7/X60adMGAFBUVATA6GPZNgnr/wB4N7Qbj12BPJ9cMGn85IKcm5sLACgu\nLnbk2ruCQCDAGxHB6/VyO+VnSinT3KHFmeD3+01zwCm1KC2LgtY6oZS6GcA8AF4A07TWK9NxLRcu\nXDiLtLgkm92IXVQfaIeqrq5miUCunD6fz7Qj0w4rpQc7FSSdkCIevfd6vdxOOR5yF2zI2Eciut2u\nvKuIRCK8k6dSKdsd9sorrwQAPPvssyxJnHDCCfjf//7H90Yqg9/vZ1UoXdKNlGK2bt3KbcrKygKA\nemrPngRJYcFgEIAh1dD8C4fD3EeBQIDHQSnFc+Doo48GAJxzzjm4+GJDAO/QoQMuu+wyAMCMGTMa\nuvRXWusejTZQa73HXwB0c16ZmZk6MzPTdCwSiehIJKJ79eqlCaNGjdIZGRk6IyND+3w+23Pl5eXp\nvLw807GMjIxmtaexVzgc1uFwWEejUR0KhXQoFGrS7/x+v/b7/RqA9nq92uv1agDa5/M1eD9Ovzwe\nj6lfDj30UH3ooYfqjRs36o0bN+p4PK4//vhj/fHHHzd4X5FIhMdhd7QTgO7Tp4/u06ePrqmp0TU1\nNXrChAm7pb8ae2VlZe3080gkYvr/D3/4g/7DH/6gJ0+erGfMmKFnzJjB8/uHH37QEtu3b9fbt2/f\n2fmXNOV5dGnOLly4MCFdhsa0wioqH3vssXj00UcBAMcccwwbGu+77z4Wc9euXcvfX7hwIQDg0Ucf\nNVnFSZWoqqpytL1255OW5GQyyaqENCLSe621SQ0itSJdFn1p+EqlUtwv5eXl2G+//QAAbdu2BWCM\nBYmtsVjM5HGg+7Yaz+hzJ5GRkcEqgsfjYUMo9WHPnj3RubPhEPv555/tT7IbIMeMxjEnJwe//PIL\nAGMOHnHEEQCAYcOG4aKLLgJg9C19/9dffwUA/P73v+dnQSnFal5LsVcuCoQzzzwTADB37lysX78e\ngKGv5eXlATAetn333RcA0K5dO7ZBHHzwwQCATZs24amnnuLz0YRtCUnHDtJtRPB4PPyA/f73v8ch\nhxwCANh///0BAGeffTbrxQsXLsTw4cMBAOvXr0+7ey+ZTCInJweA4Y4kfbdLly6YPHkygLoF9JFH\nHuG+9/v9traNQCDA57DzGLUE1A5pM5CeJPJCHH744TjssMMA7NlFwe/313NF/vLLLzjyyCMBADNn\nzuQ5G4lEeIOjOQ0AP/74IwDgoIMOwqeffgoA6Natm2MeHVd9cOHChQl7paRAO/oDDzwAwCB50Oqa\nSqWY9JGZmYmVKw1PaCAQ4N2vQ4cOAIDHH38c3333HQDgk08+Yauv1WvRUpCEEIlEcMoppwAALr/8\ncn5PIrdEcXExi4P9+/fHPvvsAwDYsGGDiTdAYriT7Q2FQuwT9/l8LDkNHjwYHTt2BAC8//77AID7\n77+ffxePx3lspBW9pqYmbV4eeT6SBKVXiXbPzMzMPSohECT/hPoqMzOT52+XLl1MXonVq1cDMKS3\n559/HgCwdOlSAMDAgQNZ2qyoqMBbb73lSBtb1aIQCoV4EK0PpnQttWtn0LfpQYlGo6y/Lly4kCfj\n0UcfzQ/eIYccggULFgCoY4pFo1FMmDABAHDiiSdi8+bNABqPgZA6t5V0JNssyUcA8Pzzz2PAgAEA\nzA/00qVL8eGHHwIAPvvsMwDAmjVrcNpppwEwFjGaHDIWwUmClYRUnxKJBPf9zTffzNdcssRgp1dV\nVfEkrq6uZtejUsp0Hnp402VTCIVCJgYgXZuo2hUVFeyydBp0T9Y4Gru4C6Du3ulveXk5v1+wYAHP\nv7feegsvvPAC3w/NJ2JEPv/889z3P//8s2mBbglc9cGFCxcmtCpJQa6siUTCRNiRpJe//vWvAOp2\n4ng8zt/9xz/+wQSaCy64AFu3buXzjR49GgAwZMgQAMABBxyAgoICAMBVV12FBx98kK+3MwQCAZZM\nvF4vt7umpoYlh3A4zEa3e+65BwAwaNAgPse//vUv/O1vfwMArFq1igNd6LxS3TnuuONMBjy6RjKZ\ndCSC0QprHAhd44ADDsCKFStM96SU4rFRSvEuJ3dtCqAC0ifdNKSW0A4djUZZ8vr4448duaY1+Mgq\nHUjYUbBlZOSbb74JwFDLyBhbUlLCkkAymeR77N+/PwCwcRoAXn31VXz7rTPpSlxJwYULFya0Kkkh\nmUyaotpoh5K7UX5+Pm655RYAdbuq3+/HfffdB8DQyUiCePrpp1n/+vXXX1kSmDlzJgDDuEiunjFj\nxvAKTRJFQ5C8g5qaGv6djK4sKyvDBRdcAMCQXgDDHnLeeecBMGwf5EaTkoc87/jx4wEYtpGjjjoK\nAHDeeec5Fg3XEBKJhIk+fcYZZ3CbXnvtNQAw8SpkTD/tZl6v1yT9kK3FaYNjQ+cjyUlGnf7xj390\n5JoEkhToWk2xk8ixo7Z7PB5bTofX6zVJyGRUPPbYY+udd9y4ccjPzwcAbNmypTm3UQ+talFIJBL1\njHN0nEC8b6AuNn3mzJn84FmTTchOpgeW/LwPP/wwP3ilpaW48cYb+bg1bNUKGZdA583IyOD3BQUF\nvFCRJX/27NlsOZZ+9Wg0Ws+Pf/jhh+PAAw/k73zzzTcAjIlCxti8vLx6kXNOIDMz06SuPPbYYwAM\nlYCMWVJlIkhxOplMch+mM75GGoVl6LTVAFxeXm47t1qCnS0GXq/XtABQO1OpFB+XDzy1zefz8fFk\nMsmbWmVlJRvFTzrpJP7diy++CMBQNZxSIV31wYULFya0CkmB4sarq6sbdAeSVDB48GBeEWnHnD9/\nPu/QMtFHXl4eM8KAOrcmiWpPPfUUG/969+7N1NgePXrgk08+abC9MnoNqNspysrKmFtw/PHHm3Z6\nABg7dixTVKPRKO+kkpNAxqN33nmHDY3btm3D119/DQDo3r07784//vhjWpKslJWV8U57++23c789\n//zz9fgQXbt2ZTUpLy+P++X111/HsmXLAJiNlU6x7giyPXJnJqlBiuhOw05CkNehz607uHTh0vdo\nTOPxuOm85FIdPnw4Tj31VAB1Ub6VlZUYOXIkAIN23lK1gdAqFgXAbIm1HgMMSicAnHrqqdwpRFb5\n+eefefClXWL79u2mLEx24bO33347AODLL79kOjLx+htCTU2Nyeovc+eRutIQUUb+jtqclZXFNOY7\n77wTgDG5aNEIh8NMgMrKymKd8oEHHkgbKYgm5llnncUP2Pvvv89q05///GcAhi5LZLCSkhLuw6ys\nLL4XAGm3gwDmh4/UKqKEZ2RkOErwsoNVfWroOzTH5cNv9T4BBj+F+vnvf/87zx26t3HjxvE88/l8\nthnHduk+WvRrFy5c/ObQKiQFGQUoLdnSn0uW106dOmHbtm0AwMzGjz76iM8lmZA+n49XTWmAJI/D\n9u3bmQb9zjvvsGegKSKujKgkycTj8fBvFy5cyByJ9u3bAzC4CYWFhQCAr776igN0TjjhBPzud7+r\ndw3a5TweDwe+DBw40ERzTkdyGL/fj27dugEwDJ7Un2VlZRx1SsZHGVT2448/MoekQ4cOtm2ThjMn\nQLun1tq0O9McWbNmDQAjYChd2bolo9FOQvB6vab5YtcOu9+1adOGPWbSE7FunZF/9eGHH2YJIx6P\nt1hCILSKRQGo0w2lGkEPsdfrZb02mUzyYkAUUJ/Px6KbJBCFQiF+sLTWfA6yM/j9fhxzjJF5/pRT\nTuFJTGJYQ/D7/SYxj9oZi8V40nu9XsybNw8AcOGFFwIwbBWHH344AHDGHMB42Mi7MHXqVABGWDfZ\nFN5++23+bjwe5wfK6WhOeQ2aeOvXr2fV7aabbkLv3r0B1Onsd955J15++WX+LYVRS+s/ZXwGnFsM\nCHZ9IKMyyYYjxevdBZqT0WiUbQO33norbwB2+SWrq6vRpUsXAMDJJ5/M3ykpKeFYn4cffhiAEX1L\naqXMzNTSeeGqDy5cuDCh1UgKFGREopUMOpIUT5/PV48qKw1IGRkZLB1YdyVrrH9WVhZbdHNycvh3\nROVtCNbry/9JffB6vbj66qsB1AUPnXbaaawyeL1eFvfGjBmD2bNnA6hTicaPH8/3T6I6YOwIdL+p\nVKqeJdsp0DUee+wxPP744wCA008/nXc/kmiklOD3+3nnysnJsU25nk7yEkkjNTU1OOCAAwAAffr0\n4e+SNwQwG3yJqFVRUWEqtAI0jWNB35GZmj0eD/MJunfvjoceeoi/L6nsQH2VlyDHdNGiRZg1a5bp\nupJ7IQl+LUWrWRQo+5CVJQYYYhZ1/Pbt2/lBIBHX4/HwBCwvLzepIHJi0jnoGkVFRejevTsAY8Eg\nqy7p/Q1hZ9V46HgqleLrPPPMMwCAiRMncnvkgiVT0ZNaIYubbNu2je957dq1HNvh8XjSlgiVFtBv\nv/3WVKSEFjLpZaBj8XicIxFXrFhh6nunU7sT5OJCqlsymWRdm/qxvLwcq1at4u/K+BG6VzmPaKEo\nLi5ucKxJHaVFT47pp59+yqqpfNClikltLykpYdWmpqaGF4hIJMJzUhaykXYZmutOelZc9cGFCxcm\ntBpJATBWamuEHoFWxJycHN6Bb775ZgCGiEsimSydlUgkeBWX56Jjs2bNYl6/1ppjIhpbde1i463/\nS0Op9EvbVS+SOwlZm4E6teOnn37ic/3888+821orMjkFmeL9s88+YyJX9+7deXckY5jkfgwZMoST\nhXzwwQe8c0YiEccNjAQp5ksC0MaNRkEykiZzc3M5/wZQRyCSv5OFbyTprSFYeS9t2rThnf3oo49m\nCSojI4O9NsXFxUynp2hHGfsSDodZJSgsLGQC3KGHHsqqECVbAeokarvqXbuKXZYUlFKdlVIfKaW+\nVUqtVEoNrz2ep5Sar5T6ofavM9kkXbhwsVvQEkkhAeA2rfXXSqlMAF8ppeYDuBzAAq31OKXUXQDu\nAjCysZNJwyJgdrHEYjFedT0eDxsESQ9LJBK8Y8r8BoB9mbJ7770XgMEPIGrzunXr8Pe//71JN74z\nSUEet37WED06FotxhBu1N5FI4MknnwRQP2sz7SQytZeTfIXKykq2GZSVlWHRokUAwO5IAOxWGz58\nOJ544gkABvuRJInx48ebIi2dYttZQXNESoVAXVk7khi6dOmCE088kT+nPpWcAbs0fDuTxuj+6LpF\nRUXseiwrKzPxYaid9913H1PZyZYhDcYvvPACJ8etrKxkt/sRRxzB0cGLFy8GAKxcuTIt6ficLOjy\nFoB+AL4H0KH2WAcA3zf2W6UUFz2hl1LKVDjl4IMP1gcffLB+7733uPhFZWWlrqys1FOnTtUHHHCA\nPuCAAzQAHY1GdTQa1UBdEZVTTjlFv/vuu/rdd981FdCgoiZnnnlmkwt2eDweftVWt9rpKxAI6EAg\n0ODnBx54oJ4/f76eP3++jsfjOh6P61gspjt27Kg7duxY7/tt27bVbdu2TUuxEusrGAzqY445Rh9z\nzDFaa62rq6t1dXW1fuedd/Q777yjAeixY8fqsWPH6tLSUtNxOQ5UrCedbVVK8bzp2rWr7tq1qy4s\nLNSFhYVaa63nzp2r586dq6PRKI+fdVypnVRwhwrwNPelteZCNFVVVaY5l0qldCqV4v8LCwv1iBEj\n9IgRI3Q4HDad5/jjj9fHH3+8rqys1MlkUieTST116lQ9derUetdsQqGhJhWDccSmoJTaD0B3AAsB\n5GutN9d+9AuA/AZ+cy2Aa524vgsXLpxDixcFpVQGgNcA3KK1LrWI1rST1oO2lKKXmYBrPzeJRJR1\neeTIkejZsyeAOuPhlVdeyXyDBQsWMHU5FAph6NChAAxxV7LGAMPVR6nZli9fztdqzGAj1YKm+LGl\naE/qQTweZ5E6FApxglkSZzdu3GjiVUi/OrH00gmZsIOSxhYUFOCLL74AYKSIA4DPP/8cvXr1AmDk\nfLj77rsBGDRnSoTr9/vTZmgkWAvYUD/Lsu/EU5AqTDQa5balUilTLoPGYFWJpOpaVFTE7lmZTjCZ\nTHK/ED182rRpfA6pzuTk5HB//+1vf+NAvQ0bNvC9yRoS9Dy01O3bogKzSik/gHcAzNNa/1/tse8B\n9NFab1ZKdQDwsdb6oEbOw42w05FlRiMAHKMwZcoUADBVxtm4cSP/TxMCMKz2VCGIrL9z5szhDqys\nrEyb3kuQ9FsAtqm8yar/0UcfoV+/fgAa5tQHg0FeOJ2kPEs92ppwhRZk8pIcd9xxTKoZP34807UB\nc9ITGovmPHRNAc2XVCplm0n7pZdeAmDYQ/79738DMPT6H374AYDRt7SAWLMeAcai31jMhLRb0YNb\nVVXFeSxlBm6gLjEK8U2AOg9UIBDguR6Px03RkzsjVO2MOyPQpAKzLfE+KABTAayiBaEWcwEMrX0/\nFIatwYULF3sJdllSUEodD+AzAN8AoKX0bhh2hZcB7AtgHYDztdY7dfoqpTSJf7R71tTUmBiI9F6W\nNSfrbv/+/Tkz8uLFi3mXKC4uZlXgo48+4hqSVLfP6vGQ+SGdhDwvvU+lUvy+a9eurB7RTvr2229z\nLL0MfAGcjzS0g6RPS4nGWmQlGAzybrZjxw6TtEXtjMfjacvibLd7Sqo7cVlGjhzJHpXCwkJccskl\nAAy1lCSaRCJRb7fdWWEgK8W8oe9apS15bsCY303xHpG0Qf1aVlZmGpsmRIE2SVJokfrgFBqyO/xW\nICeunYpy2GGHmURJwODs00IhM+pYVSmZ4MWFi0aQXvXBhQsXv020KprzbxUk4kkSFlAnPubm5rK4\nS6L48uXLbTM1twbJzsVvG676sJtBjD+ttUnPJPcVMfEagszx58JFM+GqDy5cuGg+XPVhN0B6Cxoi\nRhUXFwOwrxOpRf7BhrJdtwaJz8VvA66k4MKFCxN+E4tCJBKB1+s1scYIoVCIGWdZWVms0xOCwSCC\nwaAp3wJFvzmFmpoa9kNnZmbanp+CURKJBPvL6b2V/Uc5I7TWpvwRexp2xVgINA5KqbTXgCA+ghU+\nn8+URNbaTvk+EAg4XmbOitzcXGbf0jha2yb7i95HIhETWxcw5+RoKfZK9cEaDi1JPJFIxFRclL7j\n8XhYdKeBKC4u5odVa+1YgU4rJKFFvpfxDFYSTk5ODifeqK6uNj34rY2bIFUe4mFY6yQ6nYaNQA+H\nPH9JSYmJkAQYfWZXTUo+dPJzGgcrNb2lyMjI4HOTygiYx1LOb/JGyVB8Od/lXHYKrWOLceHCRavB\nXu2SlIUwGqoAbFeOS+7KdjTZcDhcrzS8U6DrSVUnkUjYZmWWEgEl72go4Uo6isI0FzIoJxQKsQRR\nXl5uSriSDkhJqiEJqjFa8Z4y3MrExHL8rQleqH2S9yLRhLoPTXJJ7pXqA4EGP5FImCz8UvyiTpU5\n7OSAEz9AhiM7vSDQYMm8jYlEwjSRrXp2VlYWD/62bdtMi4GMOGwNi4Fc0OwW4VAolLbYB0I0GuUF\nR8Y+yLbZ1SuVCIVC3G67MXMC7du358phhFgsZmsTqKmp4cU0OzubQ6ZpMQiFQvzeyY3MVR9cuHBh\nwl4pKZDILEvNyXz9lANv0KBBnFfwqKOO4t/RjrJ8+XKccMIJfF6Zez8dO1swGLQ1uMkalATJZyCL\nM2AEUsnM1a0BJI3l5ORg//33BwDMmzcPH3/8MQDg0ksvNUVVyt+0FNQHUi0pLy+v5/0A6nZ/ObYy\nglEaGtNVkk9KCZ06dQJg5ACRkqJUA6htwWCwnqrr9Xr5/quqqhwzQO+Vi4JVZL799tu5PHu/fv1M\nbkf5AJHVlh7+Aw88EAcffDAAo8hKupKr0ASziohSRCV07doVgGFBpzTjUj8H6iZFKpVqViWjdGO/\n/fbjYr+RSISTxPj9/gb14JaCbC2lpaUmu4t1Uff5fLYLkbTkh0IhHhNqb0VFhaOh9DJcn9QBj8fD\n7T3qqKM4cev//vc/LiS0ePFiXuho/u7YscOkKjvl6m0dW40LFy5aDfZKSYFW8aOOOgoAMGrUKFOg\nEa26a9euxYIFCwAYSUtoVaV0WJmZmXjkkUcAAGeeeWba07HV1NSYRDza3aWoev311wMwqmDTTrt9\n+3aWeJRSfB8yp+CeBO2uN954IyeDycrKwowZMwAY952udko1i8ZNGpXJj+/1ek3GZDLgVVZWcvvL\nyspYIksXryIUCnE7pefovffeA2DUG6XCMWPGjOHcnQMGDOBUdzJ6VqpJTrV5r1wUrHn+Vq1axQvF\n//3f/7FKMG/ePHz66acADPGRxMt//etfAIBzzjnHVCDV6YxLhIZcRfJ6NHlpQpSVlbH64PF4eLL6\n/X7TotUaXJLDhg0DAFxwwQW8OBcVFXFOxOrq6nqqk1N9TfefkZHBD8X111/P76ls+6pVq7jSlc/n\nQ48ehmdu48aNWLt2LQDggQce4HbRohKNRh3dJCoqKniu0rx48cUXufrTe++9h+eeew4AMGPGDK4G\nde+992L48OEAgE2bNnHbGkru2xK46oMLFy7MaEpxiHS/sIvFP/x+f70iMrIYhiw+4vP5dOfOnXXn\nzp25CMePP/6oc3JydE5ODhcDsRYIcfK1syIzw4cP18OHD9dlZWW6rKxM//DDD/xZNBrVGRkZOiMj\nw/SbdBZXoSI6gLmYjbWoy4knnqg3bdqkN23apLXWXMzmggsusB2fxgrjNFLMxFQEx+/3c6Ga6dOn\n6yVLluglS5boiooKHuNYLKZjsZjWuq44i9Zal5SU6JKSEq11XXGWgw46SBcUFOiCggK+RlOK/TTn\nJe+vZ8+eumfPnlprrSdNmqQnTZrE/UN9dMopp+hTTjlFa611bm6uzs3N5d8Hg0FTH8sxa+DVpGIw\nrqTgwoULE/ZKmwIZ68igKLPoxmIxth1IV18ikcDVV18NoM5NuXbtWjba5OTk8HunqzlTe6VRTGZo\n9vv9GDx4MIA6F1tOTg5/t6KiwuRuIv08nSxB0kslUy4UCvHx7t27AzAqILdr145/R7UPP/nkE26f\ntVDLziDZfYlEgg1pZJT99ddf+dqPPPII6+Jer5dtMH6/n6/z/fff8+dkXFy5ciUOPfRQAIZRkgLg\nRo8ezZWpqbhQMpl01NYkjYHEkYnFYpg9ezaA+rYhSuj7zDPPcM1OsuHIDN/WzOQtwV65KFgnViqV\n4gdPa22iBJOlPj8/H9dccw2AuniIWbNm8cMmH1injXbUNqUUD5wcUI/Hw3Rrwvfff28qpkIPRTAY\n5PtP16IgU775/X5eFOSEpjLqxKsAgC+++AKPP/44gLo0+oCxiDV1UZDUXaCO0i09NZTOv3v37qaY\nl6lTpwIAJkyYgG3btgGoKwMQDodRWFhY73pPPfUUp4G/6KKL+Np33nknADS56HBToZRio/Jll10G\nAPj222/x+eefAzBvSNFolD0mo0aN4r5t3749AKMvydCYTCYdK1HQYvVBKeVVSi1VSr1T+39XpdRC\npdRqpdQcpVR6g9JduHDhLBwwEo4AMBvAO7X/vwzgwtr3kwDckC5DI1UGBuoqDlOVY+trwIABuqKi\nQldUVOhFixbpRYsWaQA6MzNTZ2ZmagA6OztbZ2dnp814ZzWwkZHzyCOPZMPYmjVr9Jo1a/QVV1xh\nMvo1dI7GDHe7+qL+tF5j4MCBeuDAgXrbtm1627ZtOpFIcJtl5W7ZZo/Ho4PBoA4Gg81qg9frNbUD\ntcY5CWrHHXfcYfptu3btdLt27Wzvyefz8bjn5eXpRx99VD/66KO6vLxcFxcX6+LiYj1r1iw9a9as\ntPRrv379dL9+/djw+Ze//MX0HTsDrdfr1fvss4/eZ599+D5khWrr9xt4pb/qtFKqE4DTAdwPYERt\nKbmTAFxc+5UXAIwBMLEl17HCrkISiZcVFRUmmwKJYiNGjODfUX1BoI4zHwqF6oUlOwVJRZXkJUlC\nIRGd9EUSJwHDF0+fW1WbdGWgq7JyAAAgAElEQVQxIhWrsrLSdA2yy1DNxJKSEkyaNAmAQRAj0HgA\nzSdZ0fjFYjE+D4nG55xzDtsOVq1ahfPPPx+AOadlMplk9cHuvGVlZTzW0WiUjwcCAaxatQoAcNtt\ntzW5vc2B1hpnn302txMAPv74YxPfRKpYMlnMxo0bAYCJTps2bcJVV10FwFyvs6WVw1qqPjwO4E7U\nlY1rA2CH1pqUmg0A9rH7oVLqWqXUEqXUkha2wYULFw5ilyUFpdQZALZqrb9SSvVp7u+1pRR9c35r\ntxLKXYJ25l9//RX3338/AIM2vGLFCgB1u7C0rHu93rRRW+V5qZ1er5d3vz59+vDOTDucNERapQMZ\nHZku+rDc6ekaRxxxBFedJgnL5/Nh5syZ/F0y7G3fvp13PxkFKo2ndvD7/WwokzknqBr31VdfzZGG\n5513HhvirMY1mgPUx5WVldxm6Z3o27cvrrjiCj5OBkY7ScMpkPeE+lgGjCWTSZYgrCUCBw4cCMAo\nMwgYngnqn2Aw6Fht0ZaoD8cBGKSUGgggBCALwBMAcpRSvlppoROAjS1vpj3kBKOHzePx8APVp08f\njBw5EoBhzR8xYgQA4Ouvv+bf0aSR9FPA2YeNxG8Zpqu15ocmGo1yjj3Jz7d7gJRSPKHtEtU6BZmw\ng9yjI0aMQEFBgalNixYtwubNm7m9dvkoZb/ahS9LWIvR0r2uWbMGgMH7p3775ZdfTKqNjBi1LvCB\nQIA/r66uZgv+sGHDOLLztNNOwxlnnAEAfMzpHI0AsGSJIRzTwx0IBHheyAU/Ho+b1M2hQ4cCqFPd\n1q9fzwuIk4mBdll90Fr/VWvdSWu9H4ALAXyotR4C4CMA59V+bSjcUvQuXOxVSAdPYSSAl5RS/wCw\nFMBUpy9gzVcYCoVMIid9Pm/ePF5Jv/76a3zwwQcAzKIxpQMvKioylRR3ErSzSS6EjJYLhULsu6ZI\nTcAc2ELisNaa26m1dsw3LREOh3mn1VrjoIMOAgCce+65vGuSFDNy5EhT4hTa5fPy8tggWFVV1ax8\nCtIwS+9JvZKkKBkoVlNTUy/vpUQikeBxGD58OB588EEAxg5Mfb5hwwY2/lJgV0PFe1qCefPmAQDz\nI+R8lNJWMpnkz04++WTmhvz3v/8FAJPaprVuVDVrKhyZ/VrrjwF8XPv+RwBHO3FeFy5c7H60Okaj\n1Atpd9Fam4qpWPUnuft0796dXWSBQADTp08HYITFWtNVaa15Z5BGnWAwyKu1lBp2dTeWeqJdtiWv\n12ubYk1+x26HTaVSaan9YGVQnnXWWQAMKYb6YNGiRQDMrlMJkhIIzbHR0L3KYiw0L4YOHYoDDzyQ\nP5f9Qn2RSqWY0iwNyZTF6Morr8S4ceMAGHk06HwPPfQQ07TTlXXa7/fjs88+AwB2MT733HNMq96w\nYQNLR1VVVRg1ahQA4NZbb2Xp5amnngJg2FekG9IpabFVLAqUOETmmbOmzyLRyG6wsrOz0bFjRwDA\ngw8+iKOPNgSVVatWsVGHOPBWSPotdbq04sqO3tUceHZGICni+f1+Fo/TlRuwOUgkEmzt79SpE8fx\nS8MsJaeRcSdOgSZ6VVWVKfs1YPj07777bgBgrwG1Q6ZQo3lCc6FHjx5s2LvkkkvY2HzSSSfx3Fqz\nZk29+SWNw04gHo/zAkeG7ylTpnB7XnnlFRx//PEAgI4dO7J66/P58MADDwAAXnvtNT6fnItOxcS4\nUZIuXLgwoVVIClI9oJ1S7pher5dFqkQiwaIh/aZLly6sJnTu3Jl/d++997Kh6OKLL+b0beRuKioq\n4nNt2bKFd4x169axWuE0D4CuIdmN0uXVGiQFpRTWrVsHALjrrrtYigHqUoGRBJYOJqhdYR+SFB56\n6CE8++yzAAypkLJoRSIRHHHEEQAMCePMM880tfeXX37hQKrPP/+cx0HyU+zuw+nUfF6vl9tEDNBD\nDjkEf/3rXwEAl19+OWdb+uKLL5ixecYZZ3DGJVkESapPTgXItboKUdKabpepWEbwdevWDQCwYMEC\n9qXLKLNgMMiiu1xMaKHIysrijozFYix+Tp8+HWPGjAFg8AZaujBIO4KdFf6GG27AhAkTAIAt/XYR\nfbsTffv2BQC8//77JqISWcxpEZZVodIBih4lG4XWmqMFb775ZlPfEtfj3Xff5eMXX3wxn0sS3Gh8\nR48ejUcffRQAcMcdd/BCTX+dVo3s1C1JZMvKymLiVDAYxPr16wEAS5cuZe8DIRKJsKobCAS4zTvx\n8DSpQpSrPrhw4cKEVqE+KKUQCARQXV3NRqbS0lLegdq2bcu7VXV1NYtXJC5StWjAqL5LPn/AiFWn\nv6SCvPHGGwCMYjBkXCwpKWH6bGlpKTPenADdh+QYSKxatYpXfKc5EruCbt26cdIPn8/H/blw4ULu\nO4LTUoKUPLxeL+/+UmokI2dZWRlThgsKCliCkP57gqS0d+rUCYMGDQIAbN68GQ899JDp+kCdhCB3\nYyeQSCQ4KQ1JBNFolKXXbdu2Yb/99gNgJPOl+UCFdYA6hqlsl5Osyz0/A2F+WEiHy8jI4Ad206ZN\nLPp///33rD5Qgg9pk1iwYAHmzp0LAPjPf/7DE2HLli082WQZcplMRFJwiW7cUMHX5qCxSMZff/2V\ndVxZyGZP4cILL2SxvaSkhPtg1KhRaXPVEWQVLa/Xy+NKY6OU4gQuo0aNsiV12YnoMlnMoYceylXE\nvvnmG6bF5+Tk8INGdo10ZMmmxUCSjeSi99NPPwEA7r77bo4lWb16NX9HRtfSc6GUcoxo5aoPLly4\nMKFVSAperxfZ2dnYvn07r9Dl5eVsDR40aBCn2vL5fCw+Uez73LlzWTpYtmwZn8MqqtOqStJIKpUy\n+XbJ6GhNCdZSkGQha17W1NSw0TGVSvHx1lAfskOHDtwv2dnZmDjRSIcxf/58/g61NxwOO0oFlvcv\nPTHyPamYZWVlpnGS1GRrYR9ZNKV79+7c96Wlpawebd26lSWSdNbTsNKR4/E4X08pxfNWqrBLlixh\nSZfaW1paapLcHCtm1NLMS068UJsZRqZAz8rK4pTVAwYM0NXV1bq6ulprrfXEiRP1xIkTdTgc1uFw\nuF5aa0rVbs1IZE3hrpQyZQSyS5FN2Z0ow1NLXtQmahdl2Dn44IM5k9Bhhx2mDzvsMMcz/jTntc8+\n+3Cqdpl2vKE+cvpF4xQKher1vRzTUCjEbbNmdbLL9ETp27XWeunSpXrp0qV6n332qZe2nq6TjoxW\njWVIoixgAPScOXM4FX3Xrl1tv0/j0cRU9G6KdxcuXDQfrUJ9IEgxVL5/9913TTH5jYHEdavoZzUQ\nWr0BdsQhJ/3Ufr+frydjLVavXs3fkand9xQ2btxoW8od2D3kKhonOxVOjqn1c8lDsI51dnY2Tj/9\ndP4deSi2bdvG5/T5fCyip6sMn5XeTu2VNH5SD4qLi5n+LEHPQjwer0fyo/O1BK6k4MKFCxNalaTw\nW4eUShKJBLvTAoEA+/9bA815bwLlzpCRnclksh7lt6SkBIsXLwZgGJKp6EskEmGpwE4qdLLICsEu\ncIkMjT6fj7kZY8aM4TlDxwDwfVojbclI29L2uovCboBMQiLfk/gbi8WYPkz8dhdNQ0NxF5K/ABj9\nTZb6Tz/9lEO+ZS5Ma07EdIH4BpLST/dBnhXAXFAHqFMtZdQt3ac1jV1L4KoPLly4MKHVBUT9FiGZ\nkDLVmEwf5qoNLYNVzJc7LmDsrhRd2L59e2YN0m8BYwe3C1ZK19iQxODxeEzXoPkSjUZZ0onFYrbq\nDUmeNTU1TaGcNykgqlWpDxQDARjikCT9SLFbEoDoc1m8hBCNRpnI4fF4TOmwAYPkQZbeWCzGYpnk\nyTe3/TTBtNb16idaC9eS+CiPyUWDyFaSoGKdpPL7exry/iTV2OmCvXaQD4SMV5DjQW3YsGGD6bey\nP2n+0fnSqU5IGwhBKWWKdrTLwSlrk8p+db0PLly4SAtahfpQW2vQtNvJAhlNSeIhS5Y3xC2Q0gYA\ntGvXzlT0gxK0/Pzzz7twF7sOufs3lJGX0nKVlZXxThEOh7lv9uQ4WrNrA8aOa7fbOlXajEC7o8yO\nLUHU31QqZRLFJUg6kIVYCLsqNTYHVs9BQwF3NDdIekilUqbMz01Ak9SHVrEokE0hGo3yAFhzz5H+\nFY1GTYklgIb1LaBuwiaTyXoirNaaP6+srGyW2GUXaWkFDbSsCmVXZr2mpmanJKmGYjGcDuvdG2En\nMmdlZXF/0nyyznN6sKSaJxP4EJz2SDRmo5AqtM/n44XO6/WaEg5b4fP5bDN5WZD+JCtKqRyl1KtK\nqe+UUquUUj2VUnlKqflKqR9q/+Y2fiYXLly0FrRIUlBKvQDgM631s0qpAIAIgLsBbNdaj1NK3QUg\nV2s9spHzaMDY1aUISqJfIpHYqaFKUnKbsqpLKutNN90EwEizLY2czaE3Sy+C3GnsyCTU1szMTFMa\ndKtY7fF4TMlZSDIpKChgIkssFrMV3Xc3yNgJ1PW/FNcDgYCppmM64Pf76xl2AbOhUR6n/o7FYiaD\ntjwOpNcr1JR5Kz0j1gjaVCplm89yJ0iv+qCUygawDMD+WpxEKfU9gD5a681KqQ4APtZaH9TIuTRg\nTnSilDLpcr///e8BGCXCn376aQDAypUr+XOpi8uQZOrsE044AVdeeSUAIzkmYEzQZcuWATByEpLY\n1Zi13Cpm0oT3er22Oh49uBUVFdh3330BAPvttx+npb/nnns43+TDDz8MwCgeSvfx9ddfczvpOtZr\ntDY4nRq9KaB+keqmVLukJd8uYY4MbZc1JJysrWGnPlhd0zJ8e2f2DJ/PZ2qbVKcbQNrVh64AtgF4\nTim1VCn1rFIqCiBfa7259ju/AMi3+7Fbit6Fi9aJlkgKPQB8CeA4rfVCpdQTAEoBDNNa54jvFWut\nd2pX8Hg82u/3mwwkgUCAuQeSitqpUyfOy0fpva0rudxJaeV/7LHHcO211wIwi21z5swBAFx11VVN\nTk5hNT5Jv/HOdu+LL76YswtTxB5g8NplTUTAMJbRedetW4cpU6YAACZMmMA7cE5Ojik1155GXl4e\nqzZW3gDteFaOSUtBKmZlZaWtCG1HEJIcioY4LumCVUW2ttN6D+R1isViJl4OoZlSTNolhQ0ANmit\nF9b+/yqAPwHYUqs2oPbv1hZcw4ULF7sZLTU0fgbgaq3190qpMQCoZHKRMDTmaa3vbOQ8mtiADUWq\nEZLJJK+eJEFIXVDWZQSAXr16ATAkAtoRKCnpZ599xiXRKOsz0HgBGGtiUDv91Ov1cnqwE088EYBR\nEozauW3bNs7q2xC2bNkCwJyt+umnn+b6gq1JSgDq68vE+9i4caMpQS7gPFMwGAzyOFRVVXERFRrf\nbt26sV3mtNNOMzEvqU1VVVVsaJRFgtIFam8gEGApwGoMlcxMWUiIIN3dTZC+0s9TUEr9EcCzAAIA\nfgRwBQzp42UA+wJYB+B8rfX2Bk8CQ33w+Xz1RHI7Sz5Q13F2BhmZIvywww7D66+/DqDOUAkYNQMB\n4MYbb+Ty9PJazaHlSquwfCCys7PRoUMHAOCQ3YyMDFZRotEof3/Hjh28UFFymXA4bKsG/frrr/jn\nP/8JAHjmmWe4SOmehCSF9evXD4BRCJYK0w4aNAgffvghAOdp2XKDoP4aOnQoV4Oimpgej4fHVHpL\npCro9/txyimnAKgzDr/xxhuOJtqRVHiCPH+XLl3w5z//GYDRbyeccAIAo79IXX7iiScAgAvVWu9j\nJ0h/7IPWehkAu4uc3JLzunDhYs+hVQREaa3rrXJWA4qdQYV2aOtv6fill16K3/3ud3ycavede+65\n/Dtate3YbE1tuzWgBTB2LsqCLHcGydgkEVXWeiDxtbq6mo1oNTU1LBpmZmZy3UGv14uRI3dKAbHN\nShyJRHintrrkAGPXoe97PB5TPQwC7cDHHnssV3Y+//zzOQNxIBDA5s2GE0qqZk5nqyYVMhwOs/H2\nkUce4XoJBJmERbYjHo+zWjlr1iwuCf/dd98BMDKFOykpaK1NAXmEW265BYDhkiapcOPGjSzpVlZW\ncik/mr+9evViaWzSpElYu3atI21sFYvCrsIu353WGuPHjwcAXHfddfz5jh07WOyih7G4uJgf6EAg\n0GjRFgkSW2Ulq2g0yu146aWXuKS4pNS2bduWzyH1bEpXT8VvMzIyOIKTiqUCZhWla9eujero9HCH\nQiF+EKSVncRkj8fDx+UCopTih37YsGE48sgjTe343e9+x1GHK1asQI8ePbh/3nzzTQBGshCZd9BJ\n0Jjl5+fzAhkKhfhBlqrdCy+8AMBYQOjzdu3asVjetm1bXoip+tjQoUPZ8+ME2rZty4WGqO+feOIJ\n5tD89NNPvEC89dZbJlsZVY6iuXLTTTdhyJAhAIy5QHaUlsKNknThwoUJe6WkYPU+5OTksO83Ly8P\nZ599NgDDAEY7wvjx47FgwQIAZostfV5TU9NkpqBSikU/KZJWVlaywfC0007jHVdalskCHolEWNx7\n9NFHOTKTOAhFRUW8k4wZM4bTtUlxvlu3brb5/iToc6thj9QUuv/27dujT58+AID+/ftze0499VQ2\ndq1bt45L0C9caHiily9fzv2an5/Pv/v888+5zcFgkCUExwqW1IL64sknn2RWqN/v5/umqs3XXXcd\n3nvvPf4dSTwvvfQSCgoKANTt3EBdzgVJRXcCJCUAYMnl9NNPZ/7Kiy++aKqFKgvGUJvIYLpixQp+\nBv785z/vclnDetjThWBkMZhdfQWDQZ2bm6tzc3P1li1buLDK6tWr9axZs/SsWbN0dnZ2vd9lZGTw\n+0gkoqPRqI5Go40WO7EW9GjXrp1u166dBqBvu+02fdttt+nq6mqdSCR0IpHQqVRKp1IpPXnyZJ2d\nna2zs7O1Ukrn5+fr/Px82+IlPp+Pi6JkZmbyPVVVVfH5tNZ6yJAhesiQIQ22tdbdazqfXUGSvn37\n6mXLlully5bpHTt2cDGYxYsX69NPP12ffvrpGqgr1GJXFGbmzJnczrvuuouPBwIBHQqFdCgUatE4\n270OP/xwffjhh2uJ4uJi7iPqH1kEKBgMcjEYiaKiIv5d3759dd++fW3nTUteGRkZesCAAXrAgAF6\n+/btevv27fqtt97SGRkZPB+zsrJMhZHo1atXL92rVy9u7xlnnGFqexOu7xaDceHCRfOxV6oPZFkm\nMSorK4st3GRtBwzRkQwxANjIRyKcpJs2h+JqDYaiRC2BQADDhg0DYK4PSCLgHXfcwaqE1pqJMVlZ\nWayGkDifSCTYSi0Di0KhEIuMFRUVbBCbNWuWbVvpvD6fz+RxkHUXAcPA+cc//hFAwz5vuzqPfr+f\njWQXXXQRB6lNnDiReRqbN2+ulzPRKYwZMwaAOedlTk4O7r33XgDmfiGj5LRp0/het2zZwiSyvLw8\nDpajbM9OF4WRc46yM//www983Ov18njLccjNzcVxxx0HAPjiiy8AAO+99x4T2C677DLH2rhXLgqk\n59FD98ADD5gqK23dajCr582bx8c8Ho9Jn5PHAUPHpoFpjAgio/Cku+q6665Dp06dABiLDC1aspgp\nwev18gNbUVFRz45h9YZQgd1zzz2X7zU7Oxt33HEHAODOO3dKGkUwGOSHpqKigtsivTbUF6FQiO/f\nmkGJ7oVsAwDwl7/8BYDRl++//z4A42Gixcvn8/Gi6zR5iVyjfr+fH5CqqipeDGgxys3NZe/ExRdf\nzOOWk5PD9z1hwgS89NJL3H5qu5MuyTZt2phiZQDDnmMXAq+U4voU119/PYf5k3cikUjg008/BWDE\nAdG8aCnT1VUfXLhwYcJeKSlYV1WpIgBgC/mMGTNYmohGo7xCk3gWCAT4HHKFbowuaqVAkyh+5513\n8m5MXAgA7D+W1OXy8nITsYis5bIN0rNBlNZLLrnE1I6Gaj4S6Boy0hRAvd/J3VB6YqT4nJ2dbdr9\nAcOCfsghhwAA/vvf/+Kee+4BUD/ZDHllioqKdtre5oIs8n/605/4GqNHj+bj1P4+ffrgxhtv5N/R\neOfk5GDGjBn8O6vE5qSUABj3T+0knH322bjgggsAGKSpFStWADC4Bz179uTvEaV9+vTpfEx6VKxj\nvKtwJQUXLlyYsFdKCrTKk77l9/vZXtC2bVuMGzcOgLFbjxgxAoBBCaVVd+zYsQCMSEUKLpLSQVOC\nxCR1mfTzzMxME5OO2knUXxmFB8A2vl9C6t+yZgVJKkqpRqUau3uxBp/ZfU6SgM/n4+uVlJSwVEQS\ny7nnnstcgAsvvNAUoSrrVjgtIRDo/mTU6WWXXYbCwkIARlAcYNh75JiR/v3222/j9ttvB2DmEDjm\n87cB7fRkiD3rrLNw7LHHAgAOPvhgHH744fV+s2rVKlx11VUAYDISE5Vc1jhpMfY0R6ElPIX+/fvr\n/v37m3zNFRUVpv/Ly8t1eXm5rq6u1lbMmDHD5D8mn35j17X658nHfNFFF+mqqipdVVWltdZ6x44d\neseOHXr27Nl69uzZ9XzeVm4CavkJPp/PdCwcDusXX3xRv/jii7qsrIzbT1wFbXSioy/iI8h2+v1+\n3b59e92+fXu9YcMGvWHDBp1IJPT999+v77//ftP9BQIBU3/a3asTr0GDBulBgwaZxlX2EY1/ZWUl\nH0smk3r58uV6+fLlukuXLnwuO25AIBBwtL12HJhAIKB79+6te/furbXWpjn03Xff6e+++04fcsgh\npnN4vV6tlNJ+v9+Wd9LAy+UpuHDhovnYK9UHcuWQf3zr1q3sIguFQixSlpaWMiWa/gfqxK9evXox\nd2H79u38u4KCgnoVfyWSyaTJSCjrBpDYWVxczHTViy66CACwbNkyPPfccwAMkZrcch6PhyP1ZOk6\nQl5eHi688EL+X1YovvTSSxvrrmZDUqlTqZTJsEoiLKlun376KQeglZSUcL/IxCF0znSADG3Tp0/H\nOeecA8BcR5LaI1WH7du3s2Fv3bp1JnGcDLA0pk7zFGRbZNlAcq0CMLXhgQceAGCONKV5qi0Zqp1y\n9+6ViwJ1yrp16wDU6eyAMeBEbsrOzmadq0OHDjz41JFLly5lzoMsMrOzBQFouCBoLBYzkacINLGG\nDx/Oi9CSJUvw8ssvc3tk9mDAWByeeeYZAEC/fv3YY5KZmcnel8WLF3PCGCfh9XpN3hBqU+/evXHX\nXXeZvjtlyhRTfAAt2FZ/e3MiUJsD6ts777wTmzZtAmD0s8zNSH9pXMeOHcuh0YC5tDuNn2P6uQXJ\nZLJepbJoNMoLWTwe50Xh4Ycf5hyiAOotWIA5X6Nbit6FCxdpwV4pKdAuRszFzZs3syVX+tKVUnx8\n69atrErQSr1q1SredUtLS20t/HYIBoOm3YXef/DBByzO9u/fn9tH1+jYsSPToEOhEKZNmwbAzA6U\nLEi6j6ysLNOOQOcFgC+//HJnXbVLiMfjttmqL7vsMpa2SMqZNWsWH5MsTgCmBDbprse4ZcsWZrBe\ncMEF6Nq1K4A6KScej3ObJ02axJ6KHTt28L3K6FeC02XjpDeH+icWi3HOjJKSEpZiRo0aZVJf7CJi\nZS0Lp+qAtKpaks0FqQlFRUWmgbUSgQCj0+j4119/DQAYPHgwk1w8Hg+7qZoSLkvnsroFBw8eDMB4\nWKxhwpK67PP5eMAlLZVUITnIwWCQr1FRUcHfv+aaa5gH72R68qysLNZLa2pq0Lt3bwDA/Pnz+TpE\nGKMEJVb4fD7WcaUq4XTiVlk8aPLkyQAMWxO5F8ktWlhYaHL1STsCbRJy8bLGhjgJuVgCRi7GV199\nFYAx96idGzdurJe02App22ooTbxA+mtJunDh4reHvVJ9INBqvn79elNuQIIUg5VSbPmnHIdFRUVs\n5U+lUiwhNCWbM11H7tCRSAQff/wxACPT8hlnnAHAHLRDUoPM4CwNpYSqqirTvdAOVl1dzaJxumDd\nHSkBiN/vx1tvvQWgTkKQuS2lhyGRSJjSk9Mu53Rqdzrv3XffzfkKa2pq2KD7448/AqjzVAHG2Ml7\ntCv151TAlh1IMiFJ6v777+fPHnnkEaYzy2I/doZapZRJvaDztrTte7X6IEEP2+OPP85qxfXXX8+D\n37NnT2bVUciy1+tl8SwcDptsETvrl2AwyBNIMhHD4bBJd6ZMQDQhhw8fbhIHSawOh8P8sMhaAHSN\nr776iuM57rnnHpO6ka6YAmrnwQcfjEWLFgEw+viaa64BAF4c5MKllLJdTOV3nHbxkb3m3//+N2eI\nKisr43b84x//AGDkQbQW8QXq17y0qjdOR0kCdf1BdUOvv/56Vml79erF9g4KyQfMLlWaI4lEguep\n9PDshIW5W0rR36qUWqmUWqGUelEpFVJKdVVKLVRKrVZKzamtRu3ChYu9BS2gJu8DYC2AcO3/LwO4\nvPbvhbXHJgG4oQnnahZVNBwO63A4bKIGUyo163dl+jA6RjRReQ678+7s+vQ+FAqZqKZt27bVbdu2\ntf3dTTfdpG+55RZ9yy236OLiYhNdmei4hFgspocPH66HDx+uDzvsMD6HUkpHIhEdiUQcpwzTS1J7\nzz77bG7Ta6+9xscb6m/qWys9uKkU8ua+KHWZpDZrrfWkSZP0pEmT+HuSYm1tt0yFJr+fDlq2z+fT\nPXr00D169DDRrinVmnVcG+s3mt9NTHW3W2jOPgBhpZQPQATAZgAnwagrCQAvADirhddw4cLF7sSu\nSgq1O/xwAOUwStLPAtAWwGrxeWcAKxr47bUAltS+0rbrua/mv2SS0w8//FBv3bpVb926Vbdt21a3\nadNGt2nThj+3kxZ254ukJpKuYrGYfv/993VOTo7OyckxfbeZwUNpe02cOFFPnDhRb968WW/evFm/\n/vrrJsmEpIM0SCpNkhR22fuglMoFMBhAVwA7ALwCoH9Tf6+1ngJgSu259K62w4Xz0FpzTEXfvn2Z\nZCVDi9NNB24qyLBbWErblHQAACAASURBVFjIhsTJkyfXS0nWsWNHpkHvaZx33nkA6nKGvv/++6aC\nt2TYbGo9U6fREvXhFABrtdbbtNZxAK8DOA5ATq06AQCdAOz5CqguXLhoMlrCU1gP4FilVARAFYyi\nsksAfATgPAAvARgK4K2WNtLF7oXWmt2l7777LgdmSaQr6rG5oHYcdNBBpuNU4IWCoDZv3lwvEGlP\ngTJFU6TpRx99ZGobuUWDwaCJDbq70NJS9GMBXAAgAWApgKtheCVeApBXe+wSrfVOR8FVH1ofaGKG\nQiH240u6NfnCQ6FQWok+jYEeplQqxQuEfOhltmqn+Qa7goyMDFa5ZCyDpMTLeAaHsVtK0Y8GMNpy\n+EcAR7fkvC5cuNhz2Ktpzvn5+QDqGIp2sCuvTpC7nN0u2BCszMXGIGP6afW3JiFpLGc/UWKrq6ub\nlEOyJfB6vaYahjIBjIwkBcwMRUlnBuqMkclkko87XfehsTGj48lksikBQ2lHeXk5sxMl5Vu2X+aC\nkJXJd0YRt86nlmCvpDlbk2pKXngoFOIH1hrDQGIZiWolJSU84eVkbk7nWqMy7ZKv0N+amhpTVJvd\nYkEWdHkeqw4sk6qmS3Sna2RmZnJx2Ly8PI4PsXvAAoGAKeHM7oAUtalN4XCYqcyyKlhrsCkopXgD\nIHtBMpmsV3UMMO5JLqLW0gaSot1EOrYbJenChYvmY6+UFKy71M4CmGjVlSnPZNCLXWn0pohi1Aav\n11svlVpDyM3N5R2surqaxUi79Fpaa5MEIncBmT+RdmanEmwQ5K4qpRur+N+QdOD1ek3l0ei+ZC3N\ndMHv93PK9A8++AAAcPnll+Odd94BYK7N2Rrg9/tN494YB4Sib1999VVOzvKf//ynKSpt+g2NewrW\nByEYDPKEbN++PYcq33///ejXrx8A4Pvvv8dDDz0EABxCDdR1vN/v5wevKeqDbIPdBJcLFQ1yWVmZ\n6eGWOffsagnKuhB0PZmcha6TDlA7g8EgX69du3asShBkNSkJrbVJB6bvpGsxkHUP4vE4jzXhhBNO\nwIsvvpiWazcH1qhMwGwvsGa9kl4gyiL2+uuvAzD6tG/fvgCMBDhOJbBx1QcXLlyYsFdKCrSDUs7F\nkpISXiXfeustTJw4EYBBd6V0Zffeey/+9re/AajLcShTiUnvQ3PaIKGUMvnFZYIXwNh9iVRTUVFh\n8v9bSSpZWVn8uYybr6mpMak86fK9U5ulUS4Wi9W7XkZGBrc9GAxy+rMdO3bUqycJOK/m0HkrKytN\n6hiJ0iSlTZ8+vVV4H6zeGsDw6ti1SXIakskk5/8kY29+fj5XnXaSL+JKCi5cuDBhr5QUyABHmZL+\n9Kc/4Y477gAAzJkzh5NgVlZW4o033gAAzJ07F1999RWAulqSn332Ge8ocqdubrYd6Vq0s0fQbltQ\nUMDZnK+++mpOw7Zy5UrMnj0bgKEbAkZNB4JVD6VdRfqxnYTUcTt37szp6zp37oxOnToBqKuH+Nhj\nj5kkFylZkNQQi8X4fHaG3ZbAThrp3LkzGxrl91qDUd3OHaq1ZqkhGo1ytrDy8nJ2md9333310vB9\n/vnnWLlyJQDDjuCUJLRXeh+s1ZSuvfZaLhJ61FFH8QNkfWDoXknM6tGjB3744QcAZoNZYyKuddFo\nyMBDnAMqz3799dfjf//7HwBg9uzZXKjmiCOOMJWrB4AzzzwT33//PZ+HBryiosLE00gXJZYKs06b\nNg1/+tOf+DgtntSeqVOnck7Bb7/9lhe1eDxuazx1ur3SM0J998orr+Ckk04CULfIDh48OG2p65oD\nv9/P80UatmmxjMfjvLG0adOGN7vbbruN1QbaTPLz81kVlun7djJ/XZ6CCxcudgEtSbLi1AstTB4x\na9YsPXPmTD1z5kwN1KUE83q9nFjD6/Xqbdu26W3btulkMqmTyaQePXo0fw9oegoua1VouoZMm9Wu\nXTt97LHH6mOPPZaTlAwbNsz0u44dO+qOHTtqAJy8ZOXKlXrlypX61Vdf1ZmZmTozM9N0Da/Xa6pM\nLatDO/UqKCjQn3/+uf7888+11lqXlpbq0tJSLVFcXMwp5ag/tdZ68uTJevLkyaaUdE1JcdfSV05O\nDvfLunXrdHV1ta6urtYDBw7UAwcO3OPJYOxeDaVay8/P1/n5+Xr27Nm6oqKCK6mXlZXpsrIyPWDA\nAD1gwAAdDAY5lVwTU92lN8lKawCJ0RMmTGARFjAX7iQVwuv1sqhJom9ubq5J1CLxszEabEOir6wx\nKYvQkt731FNPmTwmMukHibSDBg0CACxcuJB90O+88w7fq1RRQqFQsyjZJLZaU4MTSLx+4okn0KNH\nnZQ5adIkAMDAgQM5QzXdRzKZxIoVKwAY8RtUTDcnJwfXX389AJi4DY2pD1beRWPqLZGpduzYgZtu\nugmAEZL8ySefADDCkq1o37498xg6d+7MatqwYcN4vlhV1HSA1KuysjITKezJJ58EAFYpAeCbb77h\nVPBURqC6upr7U2tdj/6/q3DVBxcuXJiwV0oK1t3GWk+RdlNJV04kErwy027+5ptvmoyL5M1oDHI3\nk3H68nhpaSnWr18PAGwJv+SSSzBz5kwA5kIf1C6grpL2HXfcwcYnWQ6+U6dOXOquKX5puQPZMQxp\nRywvL2fJ5LTTTmPj4L333sv9cscdd3CtgjfffBOA4X2gtp1zzjkYMWIEAOCmm25iI9iwYcPYE+E0\nxVj2wciRI/neRo0aBcC801Mg0qxZs3D00UZ0f1ZWFk4++WQAhqRE3iGqudBYDZBdARmgZT0MGo/l\ny5dzEFdVVRV++uknAMDf//53ZjJKpmtDkZYtwp62J+yKTSEUCtVLaU32AKlbRSIR1rn3228/1ofX\nrl2r165dWy81fFP1c4/HY5sEVKaRB8A67rhx4/S4ceN0eXm5vvTSS/Wll17a4H3Qq6CgQB999NH6\n6KOP1k899ZRet26dXrdunR4+fPgu6eoej4dT2FvTmQNGavpFixbpRYsWaa21HjJkiB4yZIgGoB9/\n/HH9+OOP68LCQp2Xl6fz8vL4d/379+d+Pe6443SnTp10p06d9OzZs1mvP/PMMxtMCW99kZ7d3HTw\nPXv21KlUSqdSKf3uu+9yO+T8mD9/vp4/f77JNrJu3Tq2+ZSVlenbbrtN33bbbSa7Tbpfbdq00WvW\nrNFr1qzR1dXV3LbNmzfr888/X59//vmm/rBrG6XVt6bWt7x2S4p3Fy5c/Nawp6WEXZEU7F4kKVhX\nUFpVH3nkEU4BPmXKFD1lypR6qy6lC2/KLkWrspQs6FzWNhQUFOiCggL9r3/9SxcWFurCwkJ94okn\nmr5DngiSQKZNm6a/+uor/dVXX+knn3zSVABGShjSQ2H3amhXofckHV177bU6kUjoRCKhH3vsMVNh\nnLFjx+qxY8fqiRMn2vbDyy+/rF9++WU9bdo0Pr7vvvvqxYsX68WLF+u3336bjzudZj03N1fn5ubq\nV155hXfYc845hz8n6/yTTz7Jn2/atIklgkgkoi+//HJ9+eWX82ebNm1qtF939ZWfn28aB6/Xq//4\nxz9y23799Vd+f/zxx5t+SxIU3bOc93bSn83rt+t9sDK3/H4/67XBYJD15LKyMtZlL774Yv4dMR5l\nchOgTj+l8+4M9B1pR5ChzEqpeiHFp59+OidBnTt3Lm655RYAwPPPP4/u3bsDAK644goAwLJly7gO\nIhVJJdD9xWKxRnV0uyhK6XEhm8MVV1zBOun48eNNffDSSy8BMKIkrfacRCKBefPmAagjPAFG0V9i\nPT700EM499xzAQCvvfbaTtvbXND4Dh48GKtXrwZQZ50HgOOPPx4AcNVVV/E4XHvttWyHqqysZILT\nmjVrmBhEYycTyziBLVu2cFg6eXj+85//cH+3adMGN9xwAwDg5JNP5r795JNPcMkllwCAqT00752s\n0emqDy5cuDBhr6Q5k9WWLK/Z2dkN5jY89dRTAQDz5s1jbwDRdouKikw5B8lSbc01aAeZC6Ehq68d\nbVruzI8++igAg7NA3yHp4LnnnuPdOJVK2aYSa6j6dUMgL4eMdqQKx1u3bsV3330HwKiWTfcUCAT4\nfSKR4P6i+6+urubdulu3blizZg0Ac8Xk6dOn805IklBLLOVS+rnxxhsBAE8//TTuvvtuAMCDDz7I\nPIoZM2YAMDgW9P7GG2+05R8UFhYiKysLAHDkkUcCgIn/4gTatGnD3px///vfAAxphqQ/ALb5FHbs\n2GFKqAIYXgwa/yammHNpzi5cuGg+GrUpKKWmATgDwFat9aG1x/IAzAGwH4CfAJyvtS5WxhL+BICB\nACoBXK61/trpRlv1JxlxJ/3KnTt3xoUXXgjA8Pk+++yzAGDiI0hGmDxHY7BLwWaNWrRKYTJDVFFR\nEUsSpaWlOOCAA/i93T3S7uH3+3l3iMfjTco8DRj3LwOTSGKR0YSkv6ZSKVtGX0ZGBreLdia/3892\njcWLF5v6jiST1atX49ZbbwVQZ3dYvnz5TtvdEKxjQ+ctLi428VXI10+ZtxKJBK699loA9cdlwIAB\nAIwo1ilTpgCokxCczJIMGOM+btw4AEY2KMDMTE0mk9z38XicxywnJ4dtUJQjhFL7EZzKlN0UQ+Pz\nAJ4GMF0cuwvAAq31OKXUXbX/jwQwAMABta9jAEys/eso6GGiCRKPxzmkd//992fKcL9+/bgm4rZt\n2zB+/HgAdaK21+s1DXhTO7WhkGWZPTqVSnH7ZDr0fffdFwAwZswYzh94wQUXYOjQoQDA5KDBgwdj\n+PDhAAzjlFyEdpbh1wqpElE7Kisr+b5leDOJ/Fb1iVQGeQ0ZGWoXJRoOh/n7zzzzDO68804AwFln\nGUXId3VRsIKo2Rs3bmRKs9/vZ1WCNowPP/zQ1D7Zbz179gRg9AX1lzWnpFPo0qULL8Q0jkDdnPb5\nfFzV6t133+V8jOFwGIcffjgA80YkDb+7LcmK1vpTAFbz62AYZeYBc7n5wQCm13pUvoRRV7KDIy11\n4cLFbsGuuiTztdaba9//AiC/9v0+AH4W39tQe2wzLFBKXQujHD2Aut3XrqaeNU8Brap/+ctfAABD\nhgzhwjDt27dno2Nubi6vqq+++irvfjI1GBkt/X4/7yqNpbZqSGS3Gq+s8e0ejwe9evUCAOy7774Y\nOHAgAGM3mzx5MgBjdwAM+vB///tfAIbritxQ1lz/Ta016PF4TPdE90B9EQqFOLUXULdDKqVYnG0o\nMYpMO0eieSAQ4P4oKiriVGKUW2LSpElcxMfj8Zh2PLtiKXJe0Hf79OnD1OVrrrnGlKeAjpMk8cIL\nL0CCRO8//OEPLKXV1NSwFCldzk4a46+66ir07t0bQJ2qSMZNAFi6dCkbm+fNm8eSglIK3377bYPn\n9Xq93M6W0p1bzFPQWuvmeg9qf2cqRU83QuJ3VlYWdxpg+IsB44a//towU5CFeeHChexLj8fjHE0m\nReBhw4ZxFiYSMwOBAE+8mpoaFhnTVcgklUqxN+TDDz9kb4jUk6nc+9lnn42XX34ZAPDPf/6TbSPy\nwfR4PI1mMrKLrgwEAvX4BjJhSzKZZH5+ZWWlqfah9DoQ5OJNi6wcu0AggLfffhsAmK9wxBFHcCRj\ndXU1t0+LaD8J2UcyCpbatnLlSj5HKBRCx44dAcCUAIYWimQyye1/7LHHWKWbM2cOHnzwQdN1nfbO\n7b///vxeLgbTpk0DAFx33XV8zUceecRULcpa6Nfr9Zq8TrKcQUuwq96HLaQW1P7dWnt8I4DO4ntu\nKXoXLvYy7KqkMBdGmflxMJebnwvgZqXUSzAMjCVCzWhag2pXO7nTAHUsrpkzZ3Kuuvvuuw8A8Pjj\nj7NH4fTTT2cDzvr16/l4t27dOELx5ptvBgCWHAi0Qjc3R2NzQHkihw4damI/0i4nMzyTdPDmm2+y\nZ+DCCy/k6MOamppGDWF2u0Y8Huc+koY1ErWBOvFaFiqR4jUhEonwd6V3Qu6w4XCYORD03Y4dOzar\nPqa8D5IAt27dyqrNsGHD2Dofi8W4zVQrYe3atWxUPf744/HPf/4TQF05eMCIAqX7S1dUZ+/evXku\nk/T7yiuvsBfF5/PhxBNPBGAYZcmLsmLFCmZeknolDcJO5utsikvyRQB9ALRVSm2AUWV6HICXlVJX\nAVgHgLJB/BuGO3I1DJfkFc1pjFKKxU+pW2ZkZPDgDRkyhGmsJOoFAgH2LNxyyy3cUbfeeiuHm772\n2ms455xzAIDFxVAoxN+ViUfStSBEo1GmWN9www24/PLLAdSJjkDdJN24cSMvGoMGDcI333wDwKAM\nX3PNNQCMHH2U57GxCUE6OWA8hLTokschmUzimGMMR9H8+fNNrkc6dyQS4fekYkm3mLRvRCIR0wJP\nlnNSS9avX29SeSTRy84lLNUfer9hwwZu/w033MCLzD333GNy8dE9yXBpunYsFuMHctOmTU2u9rWr\naNeuHY8FLTj9+vXD1KlTARiux9NOO63e7x577DHuT7tkKtFo1LEFrNFFQWt9UQMfnWzzXQ3gppY2\nyoULF3sQezpCUkZJyug9GRfu9Xr1hAkT9IQJE3RlZSVHte2///56//331w899BDnr9Na66FDh+qh\nQ4fWi8YrLy/X5eXlevTo0Xr06NGmz+R3nYzik69gMMhRgoMHD9Y7duzQO3bs0H379q2XpwCAKVLx\nqKOO0kcddZSurKzUBx10kD7ooIM0gCbnKQgEAqZIS3p16NBBd+jQQa9evZojOAH76MpgMKhzcnJ0\nTk6OqY30vqCgwPZ3xx57LOeepGtY71XmypTvG3vNnj1bz549W5eWlnI+Ba21rqys1JWVlVqCcknG\n43E+dvLJJ5vyNzQhJ0GLXm+//bauqqrSVVVV3Ibi4mKOUNVa8zzVWvP9ZWVlmeYDAFOEblNyi2Jv\nipJUSpnYfoC5ZmIymWQ9LBAIsE2AmGFt2rRBYWEhAKMqlHQ/yaxG5AqinIKRSMSUZtspRpgV0kNA\nlvp58+YxweaNN95gVWLhwoUADBsK6fuhUIhT0YfDYRx33HEADD25sfoJMgU63ausm0nqx3vvvcc5\nDgcMGMCuUY/Hw1b77du31+PYy/+JdAMAXbt25XEaMWIEi/zEaJSRflYXsFTprJCut2QyicsuuwyA\nEVFI0YWHHXYY579ctmwZAOCiiy5iO8GcOXPYBfzll1/y+JSXl9e7ZjgcdjRP43vvvcduRprf1L/U\nBlIP3njjDfakxWKxevYjGR28Mxd+c+HGPrhw4cKEVhEl6fV6dSgUQmVlpck/Lg0qZIB79tln0b9/\nfwB1+QyfeeYZzJkzBwDY9w+YKxEDDRdtEe0A4Hy9Q0Lbtm2ZhwDU+alPPfVUpjcvWrQIgFE6nXZP\nydn44YcfeEcm7vzOYHfPwWCQd1vafXr16sW7ZygUYj7BypUr+RyxWIzfE+LxOHsAfD4frr76agCG\nkbdzZ8M7XVhYiKeeegoAOLZA7nqSHm6lWEvuBGDOUyErfssdXY67nEOyL4jsRgQqK2hsrF4wJ0GS\naSqV4v4IBoN8z3LuStIaSTOy2ncikWiKpOBGSbpw4aL5aBWSAjEiG+IHWLPf0EpKkL+RVZCBup3C\n6/3/9q49uKrq3P/WOSeH5CQhCSQ20ljoraKC6MUyF6KOFrhaZBC9HTrKCCq0pRaq3ltGJcOjtdW2\ntnfgKlWvYr0OFlApFB0UH6AU+1Kp8hTw+hpAURN53JDXyUm++8c+35dv7exjQjg7j7p+M3vOPvu1\nHnvttb73F5UZVDvD6Nk1rKzEQRSIXv2j0ajwlffccw8AYMqUKZY6lS3h7rzzTvHDnzlzppVT4fMQ\niUQsa8SgtnJ8B52ibPny5bK6Dx06VOIMsFrtmmuuEblFeXm5teKzFeOvfvUr8WDUeTd1FGyuh6Ya\ngBOj7oKcw7ieqVTK6n/dfp2Lw98v2czmzPXlMrg+RJQx9gZTEK2trUK96EzU2jmwE6r0TlEKPa55\n0NoHt7VtN9xwAy1btoyWLVtmSdBfeeUVGj58OA0fPjy0su+88046duwYHTt2jIjaMkRxFigt3Wdp\nP2Pr1q20detWmjRpkvXM7oyO7LaMm4vm7ODgcOLoVeyDQzC04MxPzoaVdZrVdA0NDWI5169fv3Zm\nzJpd8yfJYWhPS50926Hb0Sn2oVfYKTi0h9bH6w+oqanJ+sD80XeygQEDBojPiDal1XpxRkNDg2UL\nwdBmzrW1taHU0yEcOPbBwcHBgmMfejHYZgOwye6w7Sn84PIoINZBZ9kWfyzM7qq7g4V/XPZBq5kA\nb4BpNSUf16rMTOrOIBWZ/zyT0GGZQWdCJpK7qx9UR/XX54MiISWTyXZ9od2+gTaz6ng8LmwPEVlx\nMb/oCAqKG6R69Ud98t/nV9UHPbcrcOyDg4ODhT5JKQQlvggyxtEzpqYC+FpjjHWf3mcKQj8vrDgL\nYUKb+TKFYIyRlUknetHt0/tagMj36ZR4vPr369dPqBt9T2FhoayAnUxa8g+NoFgNmag/vfrzeOZ4\nIPv37xctUXNzc9Yctxyl4ODgYKFPChqZn+XVLBKJZAxLpqMAawoB6Fx0HWOMCPz6om49iFfVrtP8\n/v2OSNr0l6GdjrgPCwsLxVxbC0ZTqZTIJbRsJChq0BcJOnwdI0geBni2IjoJkA4yzOf1mNTOhBnQ\nKUFjn5wUThZM7mpJOhFZA1Xvh+UT0Z3QH70eYIygwcrgiSWRSFiTBCMoz6W28e+LbFdY0AZe2hNT\nG4Nxf2USCOuP/wSF385L0sHB4cTRJwWNjCAPOWOMFbGITXDz8/NlNvUnaQkCr465ubmyqnaXKjIM\n6DR2euX2x0cAbPXtTTfdJKnejh49Kin5+FlLliyRuBaaUojFYvI/EonI+wkzPkFfgKY2tScmj1nt\n4Zmfny/XNDY2Bibw0WOSPW0zZWDvLPok++C398/Ly5P9RCIhYbErKyuF1Lrgggtkn8NyRSIRCXqy\nbds2Sdy5d+9eGfw6wWi2wl11JzKxPtyHPLE2NTXJflFREe644w4AwHe/+10rJyYH+mCy9ZNPPhGX\n65UrV0p0Zf+A7Yt9FwYyhWLn93HeeefhvPPOAwBcfPHFItu56qqrJCDMt7/9bQBeugCeeLXm53Pg\n2AcHB4cuoBOxDh6BlwFqlzr2awB7AewA8AcAxepcFby8D/sAfDPMeAociXj37t3U1NRETU1N5Ecy\nmaRkMklEJNF+OXJuKpWSCL+pVIoaGxupsbGR6urq5P4NGzZY0X772tavXz+J9MuRpAEEtmny5Mk0\nefJk2rFjB1VXV1N1dTUREa1Zs4bWrFlDV1xxBc2YMYNmzJhBhw8fpsOHD1sRk5cuXUqDBg2iQYMG\nWc+Nx+MSoTkSiVhRiL+IW1FRERUVFVFpaSmVlpYSALrwwgvpwgsvpO3bt1vjl8enRl1dHdXV1VnP\njEQi1rvOsGUtmvOjaJ+K/kUAVUSUMsbcDW8iuN0YMwzANQCGAxgEYKMxZigRZdXQnUkt5sOGDRsm\n55qbm60Ydzqas87Lx9cyOdva2mqZPOvEGkx6B0nZezs0uc7s07Fjx9qxE8XFxRLNecSIEcKOLV26\nFD/60Y8AeH3EpC+nkr/kkktQVVUFwMu8dfrppwPwkv9yBGoicr4OaRQUFLTT4JxyyimYNm0aAODc\nc8+1IjJpnxFmY3VcSWbjTiTZcEfoUip6InqBiFha9Td4OSMBLxX940TURETvw6MY/iUrNXVwcOgW\nZEP7MBPAE+n9L8ObJBicir5TiEQi7eLXAXYE39bWVhGIcQq2lpYWEWrl5+fj4MGDALy07s888wyA\n9sFCAC/tGK94QJtJaWNjY6BNQlcpBE5Xtn//fonEPHjwYKnPtGnT8P3vfx9AmwSZBUyAlyqO05Mf\nP37cil/QkZ6ay4jFYu0MkYA2auvMM8/EuHHj5DzHZZw/f36gtoIzf+/atQsbN24E4OWs4Ejbzzzz\nDCorK6UMpliCgsL4HX8+z8ApGo1aDloaWqjK5XB9GxoaZF+nCEwkElI3HZk6KDJ0NhAUXXzatGmY\nNWuWHN+xYwcA4MCBA7j00ksBeBQBx+PkNHdAm6A4W1QCcJKTgjFmPoAUgBVduHcWAOkJf8BODT/5\neeWVVwKAJOKMRqNiAz5//nz8/Oc/B2Ab6QQl9dCWZNFoVAZhtjUyXJ/du3fLYJw4cSLOPvtsAN4g\n5Y+aX/zq1asxapQnKJ45c6YEdD1+/Li0KRqNdlpN6k9y4r9v2LBhVrsffvhhAF6AFK058H/cyWQS\n+/btA+DlvFy8eDEAjwX505/+BAAYN26cSMYz+aAwtHpOf5Ackl0nSyktLbUsM/m4voZ/k8mkjJFI\nJCIaqCNHjsgikUwm200K2bZiJRWk9eqrrwbgBczlsf/CCy/g+uuvBwBMnz4dkydPlnt/9rOfAQCe\nesrL55xIJKz6cYJg1px1FV2eFIwxNwCYBGA8tY2mTqeiJ6KHADwEAGnBk4ODQy9AlyYFY8wEALcB\nuISItHL0aQArjTGL4QkazwDwWkfPI6J2VEIikZBZXqcqz8nJwZIlS2QfAGpqamQFu//+++UZOs5C\nJg8ybQAVljCMU7PNmTNHyqutrZXs2WvXrsWaNWsAtKVei0QiOP/88wF4qc04Gc6RI0csI6zO6v9b\nW1sttoP7k1fPiy++WPpq9erVePPNN+XeoHgJmnTn1Xrjxo0YM2YMAODll18WtmnBggUixOTU8IcO\nHQqkFPR7Ki8vl3R6TDJzff1lRyIRiyrQ6dq5DdxXdXV1QhUyxQDA8pTl49kky/m5LMTm9H/GGOn7\nHTt24Gtf+xoAL5M2j4cVK1bgscces57lNx/vtqzTGVLRVwHoB+DFdCf+jYhuJKLdxpgnAbwFj62Y\nk23Ng4ODQ7joair6337O9XcBuKtLlYnFLF41yJEmlUq14/NKS0slXdzRo0ct4Zvmk/nZvBpkWl2z\nnQBk7969ALxVAqxkqwAAEYxJREFUi5Pf3n333dizZ48cZypFJzTZuXMnAG8VZB/6Xbt2WdQN88Ad\nUQqaqtDgPhkxYoT0y7Zt2+R4Xl6erEBaEMzQx3Rk57Vr10rauGuvvRaPPPIIAM8Kj8Grtf+ZgwYN\nAuBZ93GSWh03gCkCLaDUz2BqRkN7yWpqo6mpSWQKWn7C7fB7j54samtrpTw91rnOOTk5QjUOHjxY\n5FHz58+X65mKqa2ttTyGM3kKnyh6je+DMcbK4qRfRDQalZfV0tKCW265BQDkAysrK5OPZsqUKVi3\nbp3cp5+jyUs/tDlztn0cWMhWV1cn5sPvv/++VS+uJw/G8vJyEUQCbXkzGxsbrYmjI18CLe3nMrQH\nI5PrsVhMzg8ePFjur62ttbzydAYowH5Px48fl0H6m9/8Rq5dsmQJVq9eDQC44oorAHhCV4ZfsMsZ\nowcMGNCOXdATm86fqOtSX19v5bfk+mrBMptj9+/fX+rJXou6fUGZr08WXF55eTkAr02ffvopAOD2\n22+X/aeeekpycOq6aJZGB8nR2c1PBs7M2cHBwUKvoRSChI1MZuXk5MiK1tLSInpx9gYbOHCg3Ltq\n1SoRNlZVVVlOIsyO8IqhLfRaWlpCDwCSn58v6iKtbtMCLl7hPv74Y1x++eUAPPaDWRCgbXUPUrP6\nwStpKpWyyHW9wgCelRwLuPbv32/dx2Xo+BM6C7RegZnKysnJsTJss4DxRFbeBQsWtCPn33nnHdmv\nqKjAgQMHAHhjpaSkBIDXn0xxfvDBBwCAV155RSwBp0+fbtlkMJ5//nn84Ac/kPrr9mQTp5xyCgCI\nwHzSpElyDGjr5xtvvFEEjbFYrB2LGI1GLao3W3XtNZMCk/pav8wfup4stD3D6NGjAQCPPvqopc+9\n+eabAQCjRo0SvfnGjRvbJTjxD3LN14URZUmTyXqyUj4gcjwSiYgh0ObNm6WuRUVF0o7OxOQL4oeD\nZDWfffaZkMx5eXnSRzr4Sjweb5fCPhaLtQv7Dni8P/O+H330kcgJ2Ejntttuk3ro+ujyVq5cKRML\nX/PSSy+JLEZrlzIFctGm6dy+Cy64QMZOfn6+9NHy5cuFrePJS7OV2QKzB1u2bAEAfPjhh6Jdamxs\nxIcfelr8WCwmrKJ+10Hm9tmUgzn2wcHBwUZnvKbC3gBQNBpt51nH+9FolCZMmEATJkyghx56iEaN\nGkWjRo2i3Nxcys3NJQC0aNEiWrRoEdXV1Vkek83NzdTc3Ew//OEPqby8nMrLy+W5eXl5FI/HrbLC\n2LhuNTU1VFZWRmVlZRk9BdnTbciQIdTQ0EANDQ00ffp06xrt7aj3gzbtDRl0LZe3fPly8cJLJpNy\nvqCgIPC5nEVaZ5JOJBLiDanf50033STefuxdWVRURHl5eZSXl2f1hfbc1PvFxcVUXFxMAKz3nql9\nvK+v5Xpt3rxZ2nr8+HHZz83NFQ9G3c5sjoVoNGrVCQDt3LnTyvLNqKmpodGjR9Po0aPJGBM4VvPz\n8yk/P79TYwFZ9JIMHcyXavYhLy9PyLaWlhY88MADADxNw/DhwwHA4gt/8YtfAPBUdmyi29LSItLw\npUuXioqMNQCRSMTil4P8LrIB3SYm8bRZNf/XZQ8dOlTOP/bYYxaZzKSyMabDujJvnEwmA02+mQQt\nKiqyNCAcqEbLBXQ9NbnOx+rr6wNJ2/Xr1+Pee+8F0ObbUVhYKPIV3Q+axdL7OppQUIJdbYKtj/O1\nkUgEl112GQDgrLPOkuvy8/PxxBNPyDXMmoXlEauN5FhboH17PvnkEzHpLigowKZNmwB4Mib2QNWa\nlc9TF3cVjn1wcHCw0CsoBdY8aCGi9ugrKSmR/0OGDMG5554LoG3GbGpqkpVr7dq14sH305/+FNOn\nTwfg6dtZAMkzNBvGAHaCFPJFdj5ZrFq1CoC32vHM7p/V/c5YI0eOFH19JBIJXEE7szLw6qn7tqGh\nQVZCfsbBgwdlxS8pKbFMkFlgSERSf23uzHWPx+NyX05OjjyvtbVVNAaacskGRcbt02bOqVRK+kj/\nnnPOOQA85yqtiVq/fj0Aj9JhwV6YWbJ1iEDAo9LYbuLMM8/Ec889BwAYO3asvKfS0lK89prnMcDm\n44Bt7PYPZ7wEtM8zyKT/kSNH8OSTTwLwrNy4I9jtefHixWIx19DQIGqoefPm4Xe/+x0AT93EGD9+\nvPy+/vrrALyAomH5PrAX4XvvvRdojacnID4/btw4y/8gyHPT73IcBD7v90L152TYvHkzvve97wHw\nSO65c+cCABYuXGh5OPoNwPr37y8ThX9Q8ge7aNEieWfcF/X19YGGZV2djIlIJiqdDUuDFwNt/aet\naHNycrolLwXXjTUdFRUVePDBBwF4fcaatJkzZ+LHP/4xAE/tXlFRIfuApzHS7z9buU4d++Dg4GCj\npzUPrH1AWnoKJaXV0lbWHDz88MPkR01NDe3Zs4f27NlDw4cPtyTrLJ29+uqr20l4N23aZEm6E4kE\nJRKJrGsftJSey/BL6fkajtt36NAhmj17Ns2ePTvjc08k1qFfm+OXgJeVldEbb7xBb7zxBhG1xbPU\nz8jNzZX+DJLqDxgwwGrzypUraeXKlUTUFmtw7NixNHbs2Hbapq7GbtQSd+7bvLw8OT9w4EAaOHAg\nJRIJmjNnDs2ZM4dSqZSMgSNHjtDChQtp4cKFgc8vKSnJ+njgbd26dbRu3Tqqr6+n7du30/bt2613\nAoAqKyupsrKSiIiOHj1KR48elViaXRgLndI+OErBwcHBQq+SKZCKnqNVN7m5uWLuWVVVJeGqOBrR\nwIEDRei4YcMGkRMsWLAA7777LgAvtBU7vDCvO3LkSCtjMvPcneHVTwTcjng8bgmwtGCTBV9lZWUA\nPCHqn//853bP0nkDOsP36iC1jKAcAdXV1SJ/YZUv4PXblClTAABbt25t57DWv39/2Y/FYuLAM2XK\nFHknyWQS9913H4C22BLZkt/odnGbmLfW5+vr6y15DqO4uFhiQJx22mkS+YplDvw/m7jooosAtEUQ\nAzznL8DrQ51OjvebmppE4MsWndpUvrW1NWu5NXrFpMCS/2QyGWgyG4/HRXhSXV0tOm8OUvLLX/5S\n/ARycnJEOvvWW2+JflsLwVj3fuqpp2LEiBEAPHfhsMATTCKRsOrBgjH9gbItxWeffYa333673bPY\nmxTwPqyO8lxqiTxDl6ezCrHX6dSpU6VfKioq8OKLLwIA/vrXv+InP/kJgDah3aRJk0Rw+5WvfEUG\ncX19vbR1woQJMpFnChV2spNw//79xWO0sbFRpPbai3TIkCEA7GjdhYWF2LBhAwCIH0WYKCwsFDd/\nLWhkj8mzzz5bFrVoNIrHH38cgDeRv/DCCwAgUbL9HqRB305X4NgHBwcHC72CUtDg2S4ejwt5rGf7\ngoICWSl59bnqqqswc+ZMAB5LwaoboM2WIT8/X6z42GPvo48+snzTsxX4MhP81nFBq/w3vvENAJ4F\nm7a21HYMekXQ7FYQtPVj0GqsWRBu98SJE8W2YsyYMUK2XnTRRfjjH/9oladJdaDtnTz77LNiWcos\nHGDr1TVOllLw3++P+3DZZZcJ2a6dterq6oQE19QGk+LaMS8bqK+vFyqFw6vNmzdP3sPUqVPx3nvv\nAQBmzJghx2tqaiQyOfd5XV2dvP/CwsLAjOBdQa/JJamNXgA7zl4mMlmb/uoovN/61rcAAMuWLRNe\nraWlRZ7HLMXcuXPFviFMaEMfHQhDH2fX2WeffRaA50k3ceJEALYHnHZV1nEHO+IjtQ2IDkyiddpa\nBsAf/fjx4zF79mwAHqvgj2q0bds2CWqTl5cnbutMIvvLzHYuST0GuIxYLCYTKk8Ey5YtE/PmhoYG\naetdd90lH9vOnTuzHpMxCGy8xBP2X/7yFwwdOhSAF3yG3eSvu+46MWqaO3cuVqzwgqYH2VJ00pvT\n5ZJ0cHDoAnraRkHbKXR26yi3I+u84/G4eOIVFBTIPts/dHdOQ+1xp8uOx+NUWFhIhYWFoj+fPXu2\nZTfBddfPy83N7dN5LrOxdeQFeuutt9Ktt95q2ac0NTXRrFmzaNasWRm9INl7NNtekv53CIAuvfRS\n2rJlC23ZsoWIiOrr66m+vp7WrVsnXrVB9/GYisViWbVT6HUyhWyAWQxSPgwtLS3tVHmZVHrZVkn6\n6+VHc3OzSMYPH/Yy9L366qsd2t+3traGUs++hI5kKuxHoBPEVFdXi/dhKpUSTUVzc7OMCSbFs92/\nDQ0NwoLx78aNG0XD4wezGkGsgR6n2aynYx8cHBws9ElKobOzoqYOTsRYJixKwe8ApDUKX//61wG0\nhery201oAV1YcR/6IjS1x32khW4cJn/37t2fSxn6n6UF3tlEJBIRAWPQs3Nycqyclx2FBQyDUuiT\nk4Iffhfik+2oMEly7ZLM+7FYTKTkOvuT1hho4yOun5sUgpFMJtvFbtQfvA52E4lErI+TWQy/x262\nkJubK+UFTVL+YDFB0Jq4MMaqYx8cHBws9BY7hWoAdQBqOro2JJS6sl3ZX4CyBxNRWUcX9YpJAQCM\nMVs7Y1jhynZlu7LDhWMfHBwcLLhJwcHBwUJvmhQecmW7sl3ZPY9eI1NwcHDoHehNlIKDg0MvQI9P\nCsaYCcaYfcaYd4wx80Iu6zRjzMvGmLeMMbuNMbekjw8wxrxojPnf9G9JiHWIGmPeNMasT///qjHm\n1XT7nzDGxDt6xkmUXWyM+b0xZq8xZo8xprK72m6M+Y90n+8yxqwyxuSG1XZjzCPGmE+NMbvUscB2\nGg/3puuwwxhzfghl/zrd5zuMMX8wxhSrc1XpsvcZY755MmVnCz06KRhjogDuA3A5gGEAphpjhoVY\nZArAXCIaBmAMgDnp8uYB2EREZwDYlP4fFm4BsEf9vxvAEiI6HcARAN8Jsex7ADxHRGcBOC9dj9Db\nboz5MoCbAYwionMARAFcg/Da/iiACb5jmdp5OYAz0tssAA+EUPaLAM4honMBvA2gCgDSY+8aAMPT\n99yf/iZ6Fj3sMl0J4Hn1vwpAVTeW/xSASwHsA3Bq+tipAPaFVF4FvAE5DsB6AAaeIUssqD+yXHYR\ngPeRliOp46G3HcCXARwAMACeaf16AN8Ms+0AhgDY1VE7ATwIYGrQddkq23fu3wCsSO9b4x3A8wAq\nw3j/J7L1NPvAg4VxMH0sdBhjhgAYCeBVAF8iokPpUx8D+FJIxf4XgNsAsNH7QABHiYgdG8Js/1cB\nVAP4nzT78rAxJh/d0HYi+hDAfwLYD+AQgGMA/o7uazuQuZ3dPQZnAtjQQ2V3Cj09KfQIjDEFANYA\n+Hci+j99jrwpO+sqGWPMJACfEtHfs/3sTiIG4HwADxDRSHhm5RarEGLbSwBcCW9iGgQgH+1J7G5D\nWO3sCMaY+fBY2BXdXfaJoKcnhQ8BnKb+V6SPhQZjTA68CWEFEa1NH/7EGHNq+vypAD4NoegLAUw2\nxnwA4HF4LMQ9AIqNMeytGmb7DwI4SESvpv//Ht4k0R1t/1cA7xNRNRE1A1gLrz+6q+1A5nZ2yxg0\nxtwAYBKAa9OTUreVfaLo6UnhdQBnpKXQcXhCl6fDKsx4Pqe/BbCHiBarU08DuD69fz08WUNWQURV\nRFRBREPgtfMlIroWwMsApoRZdrr8jwEcMMacmT40HsBb6Ia2w2MbxhhjEul3wGV3S9vTyNTOpwFc\nl9ZCjAFwTLEZWYExZgI8tnEyEelwWk8DuMYY088Y81V4ws7Xsll2l9DTQg0AE+FJZN8FMD/ksi6C\nRzbuALAtvU2Ex9tvAvC/ADYCGBByPb4BYH16/5/gDYR3AKwG0C/Ecv8ZwNZ0+9cBKOmutgO4A8Be\nALsAPAagX1htB7AKnuyiGR6F9J1M7YQn7L0vPf52wtOQZLvsd+DJDnjM/be6fn667H0ALg9z3HV2\ncxaNDg4OFnqafXBwcOhlcJOCg4ODBTcpODg4WHCTgoODgwU3KTg4OFhwk4KDg4MFNyk4ODhYcJOC\ng4ODhf8HKI3OoWAqVWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_n_images = 25\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "\n",
    "mnist_images = helper.get_batch(glob(os.path.join(data_dir, 'mnist/*.jpg'))[:show_n_images], 28, 28, 'L')\n",
    "pyplot.imshow(helper.images_square_grid(mnist_images, 'L'), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CelebA\n",
    "The [CelebFaces Attributes Dataset (CelebA)](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset contains over 200,000 celebrity images with annotations.  Since you're going to be generating faces, you won't need the annotations.  You can view the first number of examples by changing `show_n_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7bc580f241d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0mmnist_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_align_celeba/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshow_n_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_square_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/deepLearning/udaicty_submission/face_generation/helper.py\u001b[0m in \u001b[0;36mimages_square_grid\u001b[0;34m(images, mode)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Scale to 0-255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Put images in a square arrangement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "show_n_images = 25\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "mnist_images = helper.get_batch(glob(os.path.join(data_dir, 'img_align_celeba/*.jpg'))[:show_n_images], 28, 28, 'RGB')\n",
    "pyplot.imshow(helper.images_square_grid(mnist_images, 'RGB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess the Data\n",
    "Since the project's main focus is on building the GANs, we'll preprocess the data for you.  The values of the MNIST and CelebA dataset will be in the range of -0.5 to 0.5 of 28x28 dimensional images.  The CelebA images will be cropped to remove parts of the image that don't include a face, then resized down to 28x28.\n",
    "\n",
    "The MNIST images are black and white images with a single [color channel](https://en.wikipedia.org/wiki/Channel_(digital_image%29) while the CelebA images have [3 color channels (RGB color channel)](https://en.wikipedia.org/wiki/Channel_(digital_image%29#RGB_Images).\n",
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a GANs by implementing the following functions below:\n",
    "- `model_inputs`\n",
    "- `discriminator`\n",
    "- `generator`\n",
    "- `model_loss`\n",
    "- `model_opt`\n",
    "- `train`\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU\n",
    "This will check to make sure you have the correct version of TensorFlow and access to a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input\n",
    "Implement the `model_inputs` function to create TF Placeholders for the Neural Network. It should create the following placeholders:\n",
    "- Real input images placeholder with rank 4 using `image_width`, `image_height`, and `image_channels`.\n",
    "- Z input placeholder with rank 2 using `z_dim`.\n",
    "- Learning rate placeholder with rank 0.\n",
    "\n",
    "Return the placeholders in the following the tuple (tensor of real input images, tensor of z data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param image_width: The input image width\n",
    "    :param image_height: The input image height\n",
    "    :param image_channels: The number of image channels\n",
    "    :param z_dim: The dimension of Z\n",
    "    :return: Tuple of (tensor of real input images, tensor of z data, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    real_image_inputs = tf.placeholder(tf.float32, \n",
    "                                      (None, image_width, image_height, image_channels),\n",
    "                                      name='real_image_inputs')\n",
    "    z_inputs = tf.placeholder(tf.float32, (None, z_dim), name='z_inputs')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    return real_image_inputs, z_inputs, learning_rate\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_model_inputs(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discriminator\n",
    "Implement `discriminator` to create a discriminator neural network that discriminates on `images`.  This function should be able to reuse the variables in the neural network.  Use [`tf.variable_scope`](https://www.tensorflow.org/api_docs/python/tf/variable_scope) with a scope name of \"discriminator\" to allow the variables to be reused.  The function should return a tuple of (tensor output of the discriminator, tensor logits of the discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    :param images: Tensor of input image(s)\n",
    "    :param reuse: Boolean if the weights should be reused\n",
    "    :return: Tuple of (tensor output of the discriminator, tensor logits of the discriminator)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        alpha = 0.2\n",
    "        \n",
    "        layer1 = tf.layers.conv2d(\n",
    "            images, filters=64, kernel_size=5, strides=2, padding='same')\n",
    "        layer1 = tf.maximum(layer1, layer1 * alpha)\n",
    "        \n",
    "        layer2 = tf.layers.conv2d(\n",
    "            layer1, filters=128, kernel_size=5, strides=2, padding='same')\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=True)\n",
    "        layer2 = tf.maximum(layer2, layer2 * alpha)\n",
    "\n",
    "        layer3 = tf.layers.conv2d(\n",
    "            layer2, filters=256, kernel_size=5, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=True)\n",
    "        layer3 = tf.maximum(layer3, layer3 * alpha)\n",
    "        \n",
    "        flatten_input = tf.reshape(layer3, (-1, 4 * 4 * 256))\n",
    "        logits = tf.layers.dense(flatten_input, 1)\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "    return output, logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_discriminator(discriminator, tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generator\n",
    "Implement `generator` to generate an image using `z`. This function should be able to reuse the variables in the neural network.  Use [`tf.variable_scope`](https://www.tensorflow.org/api_docs/python/tf/variable_scope) with a scope name of \"generator\" to allow the variables to be reused. The function should return the generated 28 x 28 x `out_channel_dim` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        alpha = 0.2\n",
    "        \n",
    "        layer1 = tf.layers.dense(z, 2 * 2 * 512)\n",
    "        layer1 = tf.reshape(layer1, (-1, 2, 2, 512))\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train)\n",
    "        layer1 = tf.maximum(layer1, layer1 * alpha)\n",
    "        \n",
    "        layer2 = tf.layers.conv2d_transpose(\n",
    "            layer1, filters=256, kernel_size=5, strides=2, padding='valid')\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.maximum(layer2, layer2 * alpha)\n",
    "\n",
    "        layer3 = tf.layers.conv2d_transpose(\n",
    "            layer2, filters=128, kernel_size=5, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.maximum(layer3, layer3 * alpha)\n",
    "        \n",
    "        logits = tf.layers.conv2d_transpose(\n",
    "            layer3, filters=out_channel_dim, kernel_size=5, strides=2, padding='same')\n",
    "        output = tf.tanh(logits)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_generator(generator, tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loss\n",
    "Implement `model_loss` to build the GANs for training and calculate the loss.  The function should return a tuple of (discriminator loss, generator loss).  Use the following functions you implemented:\n",
    "- `discriminator(images, reuse=False)`\n",
    "- `generator(z, out_channel_dim, is_train=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    g_model = generator(input_z, out_channel_dim)\n",
    "\n",
    "    d_model_real, d_logits_real = discriminator(input_real)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=d_logits_real,\n",
    "            labels=tf.ones_like(d_model_real)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=d_logits_fake,\n",
    "            labels=tf.ones_like(d_model_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=d_logits_fake,\n",
    "            labels=tf.ones_like(d_model_fake)))\n",
    "    \n",
    "    return d_loss, g_loss\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_model_loss(model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization\n",
    "Implement `model_opt` to create the optimization operations for the GANs. Use [`tf.trainable_variables`](https://www.tensorflow.org/api_docs/python/tf/trainable_variables) to get all the trainable variables.  Filter the variables with names that are in the discriminator and generator scope names.  The function should return a tuple of (discriminator training operation, generator training operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tf_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in tf_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in tf_vars if var.name.startswith('generator')]\n",
    "\n",
    "    d_train_optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "\n",
    "    operations = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    g_update_list = [opt for opt in operations if opt.name.startswith('generator')]\n",
    "    \n",
    "    with tf.control_dependencies(g_update_list):\n",
    "        g_train_optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate, beta1).minimize(g_loss, var_list=g_vars)\n",
    "    \n",
    "    return d_train_optimizer, g_train_optimizer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_model_opt(model_opt, tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Show Output\n",
    "Use this function to show the current output of the generator during training. It will help you determine how well the GANs is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "    pyplot.imshow(images_grid, cmap=cmap)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train\n",
    "Implement `train` to build and train the GANs.  Use the following functions you implemented:\n",
    "- `model_inputs(image_width, image_height, image_channels, z_dim)`\n",
    "- `model_loss(input_real, input_z, out_channel_dim)`\n",
    "- `model_opt(d_loss, g_loss, learning_rate, beta1)`\n",
    "\n",
    "Use the `show_generator_output` to show `generator` output while you train. Running `show_generator_output` for every batch will drastically increase training time and increase the size of the notebook.  It's recommended to print the `generator` output every 100 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape, data_image_mode):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    :param epoch_count: Number of epochs\n",
    "    :param batch_size: Batch Size\n",
    "    :param z_dim: Z dimension\n",
    "    :param learning_rate: Learning Rate\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :param get_batches: Function to get batches\n",
    "    :param data_shape: Shape of the data\n",
    "    :param data_image_mode: The image mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    # TODO: Build Model\n",
    "    _, img_width, img_height, img_channels = data_shape\n",
    "    \n",
    "    real_input, z_input, lr = model_inputs(\n",
    "        img_width, img_height, img_channels, z_dim)\n",
    "    \n",
    "    d_loss, g_loss = model_loss(real_input, z_input, img_channels)\n",
    "    d_opt, g_opt = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "    \n",
    "    n_images = 25\n",
    "    index = 0 \n",
    "    print_every = 10\n",
    "    show_every = 100\n",
    "    losses = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch_i in range(epoch_count):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                # TODO: Train Model\n",
    "                index += 1\n",
    "                batch_images *= 2.0\n",
    "                z_sample = np.random.uniform(-1, 1, (batch_size, z_dim))\n",
    "                \n",
    "                _ = sess.run(d_opt, feed_dict={\n",
    "                    real_input: batch_images, \n",
    "                    z_input: z_sample,\n",
    "                    lr: learning_rate\n",
    "                })\n",
    "                \n",
    "                _ = sess.run(g_opt, feed_dict={\n",
    "                    z_input: z_sample,\n",
    "                    lr: learning_rate\n",
    "                })\n",
    "                \n",
    "                if index % print_every == 0:\n",
    "                    train_d_loss = d_loss.eval({\n",
    "                        real_input: batch_images,  \n",
    "                        z_input: z_sample\n",
    "                    })\n",
    "\n",
    "                    train_g_loss = d_loss.eval({z_input: z_sample})\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(epoch_i+1, epoch_count),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    losses.append((train_d_loss, train_g_loss))\n",
    "                                \n",
    "                if index % show_every == 0:\n",
    "                    show_generator_output(sess, n_images, z_input, img_channels, data_image_mode)\n",
    "\n",
    "       \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MNIST\n",
    "Test your GANs architecture on MNIST.  After 2 epochs, the GANs should be able to generate images that look like handwritten digits.  Make sure the loss of the generator is lower than the loss of the discriminator or close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n",
      "0.002\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'real_image_inputs' with dtype float\n\t [[Node: real_image_inputs = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'real_image_inputs', defined at:\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-6e487f98eaa5>\", line 16, in <module>\n    mnist_dataset.shape, mnist_dataset.image_mode)\n  File \"<ipython-input-12-3bc2ab2e18a5>\", line 17, in train\n    img_width, img_height, img_channels, z_dim)\n  File \"<ipython-input-6-45bd21a757be>\", line 15, in model_inputs\n    name='real_image_inputs')\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1520, in placeholder\n    name=name)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2149, in _placeholder\n    name=name)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'real_image_inputs' with dtype float\n\t [[Node: real_image_inputs = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'real_image_inputs' with dtype float\n\t [[Node: real_image_inputs = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e487f98eaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     train(epochs, batch_size, z_dim, learning_rate, beta1, mnist_dataset.get_batches,\n\u001b[0;32m---> 16\u001b[0;31m           mnist_dataset.shape, mnist_dataset.image_mode)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3bc2ab2e18a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape, data_image_mode)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     })\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0mtrain_g_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_sample\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     print(\"Epoch {}/{}...\".format(epoch_i+1, epoch_count),\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \"\"\"\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3795\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3797\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'real_image_inputs' with dtype float\n\t [[Node: real_image_inputs = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'real_image_inputs', defined at:\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-6e487f98eaa5>\", line 16, in <module>\n    mnist_dataset.shape, mnist_dataset.image_mode)\n  File \"<ipython-input-12-3bc2ab2e18a5>\", line 17, in train\n    img_width, img_height, img_channels, z_dim)\n  File \"<ipython-input-6-45bd21a757be>\", line 15, in model_inputs\n    name='real_image_inputs')\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1520, in placeholder\n    name=name)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2149, in _placeholder\n    name=name)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/kelvin/anaconda2/envs/tf_1.0/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'real_image_inputs' with dtype float\n\t [[Node: real_image_inputs = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "z_dim = 100\n",
    "learning_rate = 0.002\n",
    "beta1 = 0.5\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "epochs = 2\n",
    "\n",
    "mnist_dataset = helper.Dataset('mnist', glob(os.path.join(data_dir, 'mnist/*.jpg')))\n",
    "#print(mnist_dataset.shape)\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, mnist_dataset.get_batches,\n",
    "          mnist_dataset.shape, mnist_dataset.image_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CelebA\n",
    "Run your GANs on CelebA.  It will take around 20 minutes on the average GPU to run one epoch.  You can run the whole epoch or stop when it starts to generate realistic faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = None\n",
    "z_dim = None\n",
    "learning_rate = None\n",
    "beta1 = None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "epochs = 1\n",
    "\n",
    "celeba_dataset = helper.Dataset('celeba', glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, celeba_dataset.get_batches,\n",
    "          celeba_dataset.shape, celeba_dataset.image_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_face_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
